{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T06:12:38.936688Z",
     "start_time": "2018-03-23T06:12:38.533915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.LongTensor' object has no attribute 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/research/Shared/2018-03-19_StageL3/anaisbrgs_StageL3/Regard.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/Shared/2018-03-19_StageL3/anaisbrgs_StageL3/Regard.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set: Final Accuracy: {:.3f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print que le pourcentage de rÃ©ussite final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/Shared/2018-03-19_StageL3/anaisbrgs_StageL3/Regard.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m#loss = F.nll_loss(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[1;32m    601\u001b[0m                                self.ignore_index, self.reduce)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m_assert_no_grad\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"nn criterions don't compute the gradient w.r.t. targets - please \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"mark these variables as volatile or not requiring gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.LongTensor' object has no attribute 'requires_grad'"
     ]
    }
   ],
   "source": [
    "%run Regard.py --no-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T06:14:01.543835Z",
     "start_time": "2018-03-23T06:14:01.408515Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\r\n",
      "import argparse\r\n",
      "import time\r\n",
      "import numpy as np\r\n",
      "import torch\r\n",
      "import torch.nn as nn\r\n",
      "import torch.nn.functional as F\r\n",
      "import torch.optim as optim\r\n",
      "from torch.autograd import Variable\r\n",
      "import torch.nn.parallel\r\n",
      "import torch.backends.cudnn as cudnn\r\n",
      "import torch.distributed as dist\r\n",
      "import torch.optim\r\n",
      "import torch.utils.data\r\n",
      "import torch.utils.data.distributed\r\n",
      "import torchvision.transforms as transforms\r\n",
      "import torchvision.datasets as datasets\r\n",
      "import torchvision.models as models\r\n",
      "import matplotlib.pyplot as plt\r\n",
      "import torchvision\r\n",
      "\r\n",
      "\r\n",
      "# Training settings\r\n",
      "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\r\n",
      "parser.add_argument('--batch-size', type=int, default=10, metavar='N',\r\n",
      "                    help='input batch size for training (default: 64)')\r\n",
      "parser.add_argument('--test-batch-size', type=int, default=10, metavar='N',\r\n",
      "                    help='input batch size for testing (default: 1000)')\r\n",
      "parser.add_argument('--epochs', type=int, default=10, metavar='N',\r\n",
      "                    help='number of epochs to train (default: 10)')\r\n",
      "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\r\n",
      "                    help='learning rate (default: 0.01)')\r\n",
      "parser.add_argument('--momentum', type=float, default=0.9, metavar='M', #default = 0.5\r\n",
      "                    help='SGD momentum (default: 0.5)')\r\n",
      "parser.add_argument('--no-cuda', action='store_true', default=False,\r\n",
      "                    help='disables CUDA training')\r\n",
      "parser.add_argument('--seed', type=int, default=1, metavar='S',\r\n",
      "                    help='random seed (default: 1)')\r\n",
      "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\r\n",
      "                    help='how many batches to wait before logging training status')\r\n",
      "parser.add_argument('--dimension', type=int, default = 120, metavar='D',\r\n",
      "                    help='the dimension of the second neuron network') #ajout de l'argument dimension reprÃ©sentant le nombre de neurone dans la deuxiÃ¨me couche. \r\n",
      "parser.add_argument('--boucle', type=int, default=0, metavar='B',\r\n",
      "                   help='boucle pour faire diffÃ©rents couche de la deuxiÃ¨me couche de neurone')# ajout de boucle pour automatiser le nombre de neurone dans la deuxieme couche\r\n",
      "args = parser.parse_args()\r\n",
      "args.cuda = not args.no_cuda and torch.cuda.is_available()\r\n",
      "print ('cuda?', args.cuda)\r\n",
      "torch.manual_seed(args.seed)\r\n",
      "if args.cuda:\r\n",
      "    torch.cuda.manual_seed(args.seed)\r\n",
      "\r\n",
      "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\r\n",
      "dataset = torchvision.datasets.ImageFolder('dataset',\r\n",
      "                                        transforms.Compose([\r\n",
      "                                        transforms.CenterCrop(150),\r\n",
      "                                        transforms.ToTensor(),\r\n",
      "                                       transforms.Normalize((0.1307,), (0.3081,))\r\n",
      "                                        ])) \r\n",
      "train_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\r\n",
      "test_loader= torch.utils.data.DataLoader(dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=2)\r\n",
      "\r\n",
      "classes = 'blink','left','right','center'\r\n",
      "\r\n",
      "class Net(nn.Module):\r\n",
      "    def __init__(self):\r\n",
      "        super(Net, self).__init__()\r\n",
      "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\r\n",
      "        self.pool = nn.MaxPool2d(2, 2)#\r\n",
      "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n",
      "        self.conv2_drop = nn.Dropout2d()\r\n",
      "        self.fc1 = nn.Linear(12800, args.dimension)# args.dimension prend la valeur default de l'argument dimension.\r\n",
      "        self.fc2 = nn.Linear(args.dimension, 84)\r\n",
      "        self.fc3 = nn.Linear(84, 10)\r\n",
      "        \r\n",
      "    def forward(self, x):\r\n",
      "        x = F.relu(F.max_pool2d(self.conv1(x), 4))\r\n",
      "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 4))\r\n",
      "        x = x.view(-1, 12800)\r\n",
      "        x = F.relu(self.fc1(x))\r\n",
      "        x = F.relu(self.fc2(x))#\r\n",
      "        x = F.dropout(x, training=self.training)\r\n",
      "        x = self.fc3(x)#\r\n",
      "        #x = self.fc2(x)\r\n",
      "        return F.log_softmax(x, dim=1)#x\r\n",
      "\r\n",
      "model = Net()\r\n",
      "if args.cuda:\r\n",
      "    model.cuda()\r\n",
      "\r\n",
      "criterion = nn.CrossEntropyLoss()#\r\n",
      "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\r\n",
      "\r\n",
      "def train(epoch):\r\n",
      "    model.train()\r\n",
      "    for batch_idx, (data, target) in enumerate(train_loader,0):\r\n",
      "        if args.cuda:\r\n",
      "            data, target = data.cuda(), target.cuda()\r\n",
      "        data, target = Variable(data), Variable(target)\r\n",
      "        optimizer.zero_grad()\r\n",
      "        output = model(data)\r\n",
      "        #loss = F.nll_loss(output, target)\r\n",
      "        loss = criterion(output, labels)#\r\n",
      "        loss.backward()\r\n",
      "        optimizer.step()\r\n",
      "        if args.log_interval>0: # rajout de la commande pour pouvoir print ou non les diffÃ©rents epoch ou juste le rÃ©sultat\r\n",
      "            if batch_idx % args.log_interval == 0:\r\n",
      "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
      "                    epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
      "                    100. * batch_idx / len(train_loader), loss.data[0]))\r\n",
      "\r\n",
      "dataiter = iter(train_loader)\r\n",
      "images, labels = dataiter.next()\r\n",
      "\r\n",
      "def test():\r\n",
      "    model.eval()\r\n",
      "    test_loss = 0\r\n",
      "    correct = 0\r\n",
      "    for data, target in test_loader:\r\n",
      "        if args.cuda:\r\n",
      "            data, target = data.cuda(), target.cuda()\r\n",
      "        data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "        output = model(data)\r\n",
      "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\r\n",
      "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\r\n",
      "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\r\n",
      "\r\n",
      "    test_loss /= len(test_loader.dataset)\r\n",
      "    if args.log_interval>0: print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
      "        test_loss, correct, len(test_loader.dataset),\r\n",
      "        100. * correct / len(test_loader.dataset)))\r\n",
      "    return correct / len(test_loader.dataset)\r\n",
      "\r\n",
      "def protocol():\r\n",
      "    for epoch in range(1, args.epochs + 1):\r\n",
      "        train(epoch)\r\n",
      "    return test()\r\n",
      "\r\n",
      "def main():\r\n",
      "    for epoch in range(1, args.epochs + 1):\r\n",
      "        train(epoch)\r\n",
      "        Accuracy = test()\r\n",
      "    print('Test set: Final Accuracy: {:.3f}%'.format(Accuracy*100)) # print que le pourcentage de rÃ©ussite final\r\n",
      "    \r\n",
      "    \r\n",
      "if __name__ == '__main__':  \r\n",
      "    if args.boucle == 1: # Pour que la boucle se fasse indiquer --boucle 1\r\n",
      "        rho = 10**(1/3) \r\n",
      "        for i in [int (k) for k in rho**np.arange(2,9)]:# i prend les valeur en entier du tuple rho correspondra au nombre de neurone\r\n",
      "            args.dimension = i\r\n",
      "            print ('La deuxiÃ¨me couche de neurone comporte',i,'neurones')\r\n",
      "            main()\r\n",
      "    else:\r\n",
      "        t0 = time.time () # ajout de la constante de temps t0\r\n",
      "\r\n",
      "        main()\r\n",
      "\r\n",
      "        t1 = time.time () # ajout de la constante de temps t1\r\n",
      "\r\n",
      "        print (\"Le programme a mis\",t1-t0, \"secondes Ã  s'exÃ©cuter.\") #compare t1 et t0, connaitre le temps d'execution du programme"
     ]
    }
   ],
   "source": [
    "%cat Regard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T08:06:23.613342Z",
     "start_time": "2018-03-23T08:06:22.862363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.LongTensor' object has no attribute 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-38738e7e1dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-38738e7e1dd9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set: Final Accuracy: {:.3f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print que le pourcentage de rÃ©ussite final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-38738e7e1dd9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#loss = F.nll_loss(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[1;32m    601\u001b[0m                                self.ignore_index, self.reduce)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m_assert_no_grad\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"nn criterions don't compute the gradient w.r.t. targets - please \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"mark these variables as volatile or not requiring gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.LongTensor' object has no attribute 'requires_grad'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Training settings\n",
    "cuda = False\n",
    "torch.manual_seed(42)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('dataset',\n",
    "                                        transforms.Compose([\n",
    "                                        transforms.CenterCrop(100),\n",
    "                                        transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                        ])) \n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "test_loader= torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "\n",
    "#classes = 'blink','left','right','center'\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)#\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(5000, args.dimension)# args.dimension prend la valeur default de l'argument dimension.\n",
    "        self.fc2 = nn.Linear(args.dimension, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 4))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 4))\n",
    "        x = x.view(-1, 5000)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))#\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)#\n",
    "        #x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)#x\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#,0):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        print(data.size(), target.size())\n",
    "        data, target = Variable(data), Variable(target) #[batch_idx].unsqueeze(0)\n",
    "        print(data.size(), target.size())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = criterion(output, labels)#\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.log_interval>0: # rajout de la commande pour pouvoir print ou non les diffÃ©rents epoch ou juste le rÃ©sultat\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if args.log_interval>0: print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def protocol():\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "    return test()\n",
    "\n",
    "def main():\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        Accuracy = test()\n",
    "    print('Test set: Final Accuracy: {:.3f}%'.format(Accuracy*100)) # print que le pourcentage de rÃ©ussite final\n",
    "    \n",
    "    \n",
    "t0 = time.time () # ajout de la constante de temps t0\n",
    "\n",
    "main()\n",
    "\n",
    "t1 = time.time () # ajout de la constante de temps t1\n",
    "\n",
    "print (\"Le programme a mis\",t1-t0, \"secondes Ã  s'exÃ©cuter.\") #compare t1 et t0, connaitre le temps d'execution du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
