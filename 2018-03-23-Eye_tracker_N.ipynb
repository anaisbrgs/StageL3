{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T06:12:38.936688Z",
     "start_time": "2018-03-23T06:12:38.533915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.LongTensor' object has no attribute 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/StageL3/Regard.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/StageL3/Regard.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set: Final Accuracy: {:.3f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print que le pourcentage de rÃ©ussite final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/StageL3/Regard.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m#loss = F.nll_loss(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[1;32m    679\u001b[0m                                self.ignore_index, self.reduce)\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m_assert_no_grad\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"nn criterions don't compute the gradient w.r.t. targets - please \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"mark these variables as volatile or not requiring gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.LongTensor' object has no attribute 'requires_grad'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-1:\n",
      "  File \"/home/nicolas/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nicolas/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%run Regard.py --no-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T08:06:23.613342Z",
     "start_time": "2018-03-23T08:06:22.862363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- 0\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2387\n",
      "-1.2835\n",
      "-1.2405\n",
      "-1.3448\n",
      "-1.1073\n",
      "-1.1072\n",
      "-1.2665\n",
      "-1.2401\n",
      "-0.8644\n",
      "-1.0721\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 0 [0/393 (0%)]\tLoss: 1.296394\n",
      "---------------------------------------- 1\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9272\n",
      "-1.2874\n",
      "-0.9434\n",
      "-1.3090\n",
      "-1.2132\n",
      "-1.3122\n",
      "-1.1052\n",
      "-1.2582\n",
      "-1.1233\n",
      "-1.1916\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 2\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.8934\n",
      "-1.2655\n",
      "-1.0500\n",
      "-1.2802\n",
      "-1.0569\n",
      "-1.3387\n",
      "-1.0593\n",
      "-1.1777\n",
      "-1.0225\n",
      "-1.1855\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 3\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1240\n",
      "-0.9279\n",
      "-1.0730\n",
      "-1.2774\n",
      "-0.8728\n",
      "-1.0584\n",
      "-1.1199\n",
      "-0.9832\n",
      "-0.9152\n",
      "-1.0826\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 4\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9658\n",
      "-0.9635\n",
      "-1.2212\n",
      "-0.8687\n",
      "-1.1137\n",
      "-1.2273\n",
      "-1.1766\n",
      "-1.2044\n",
      "-1.1320\n",
      "-1.0010\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 5\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1238\n",
      "-1.0854\n",
      "-0.8201\n",
      "-1.0334\n",
      "-0.9208\n",
      "-1.1484\n",
      "-0.8312\n",
      "-1.1663\n",
      "-0.7937\n",
      "-0.7083\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 6\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0854\n",
      "-0.7207\n",
      "-1.1808\n",
      "-1.1884\n",
      "-1.2419\n",
      "-1.2349\n",
      "-0.8687\n",
      "-0.6542\n",
      "-0.7133\n",
      "-0.9240\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 7\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0723\n",
      "-0.9315\n",
      "-0.9614\n",
      "-1.0519\n",
      "-0.9241\n",
      "-1.3185\n",
      "-0.9676\n",
      "-1.0818\n",
      "-1.3193\n",
      "-1.2917\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 1\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 8\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0340\n",
      "-1.0126\n",
      "-1.0749\n",
      "-0.9076\n",
      "-1.0955\n",
      "-1.1597\n",
      "-1.1996\n",
      "-1.1306\n",
      "-1.1642\n",
      "-0.8810\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 1\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 9\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2199\n",
      "-1.2184\n",
      "-1.2406\n",
      "-1.2054\n",
      "-1.1812\n",
      "-1.1445\n",
      "-1.1122\n",
      "-1.1587\n",
      "-1.1696\n",
      "-1.1021\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 10\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2110\n",
      "-1.0846\n",
      "-1.1784\n",
      "-1.1236\n",
      "-1.1605\n",
      "-1.0849\n",
      "-1.1849\n",
      "-0.9930\n",
      "-1.2021\n",
      "-1.2041\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 0 [100/393 (25%)]\tLoss: 1.356515\n",
      "---------------------------------------- 11\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1704\n",
      "-1.3339\n",
      "-1.2133\n",
      "-1.1686\n",
      "-1.0676\n",
      "-1.2017\n",
      "-1.0882\n",
      "-0.9735\n",
      "-1.2818\n",
      "-1.2394\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 12\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0900\n",
      "-1.2258\n",
      "-1.2830\n",
      "-1.1402\n",
      "-1.0550\n",
      "-1.2626\n",
      "-1.0856\n",
      "-1.1877\n",
      "-1.1189\n",
      "-1.0673\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 13\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0471\n",
      "-1.2409\n",
      "-1.0941\n",
      "-1.1896\n",
      "-1.2120\n",
      "-1.1133\n",
      "-1.1944\n",
      "-1.2856\n",
      "-1.2866\n",
      "-1.0403\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 14\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1426\n",
      "-1.1628\n",
      "-1.1805\n",
      "-1.1716\n",
      "-1.2538\n",
      "-1.2261\n",
      "-0.9612\n",
      "-1.1379\n",
      "-1.1080\n",
      "-1.0520\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 15\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0050\n",
      "-1.2344\n",
      "-1.0368\n",
      "-1.2122\n",
      "-1.0171\n",
      "-1.1044\n",
      "-1.2142\n",
      "-1.1004\n",
      "-1.0894\n",
      "-1.0303\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 3\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 16\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1244\n",
      "-1.2204\n",
      "-1.2582\n",
      "-1.0672\n",
      "-1.1166\n",
      "-1.2803\n",
      "-1.2003\n",
      "-1.2003\n",
      "-1.1841\n",
      "-0.9616\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 17\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1249\n",
      "-1.2696\n",
      "-1.2978\n",
      "-1.3368\n",
      "-1.1160\n",
      "-1.2593\n",
      "-1.2654\n",
      "-1.1991\n",
      "-1.2219\n",
      "-1.3313\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 18\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3180\n",
      "-0.9966\n",
      "-1.3211\n",
      "-1.0930\n",
      "-0.9565\n",
      "-1.1066\n",
      "-1.0419\n",
      "-1.1851\n",
      "-1.0985\n",
      "-1.2188\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 19\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1698\n",
      "-1.0801\n",
      "-1.1894\n",
      "-0.9001\n",
      "-0.8459\n",
      "-1.1368\n",
      "-1.1514\n",
      "-1.1913\n",
      "-1.1849\n",
      "-1.0258\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 20\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7528\n",
      "-1.1381\n",
      "-1.1833\n",
      "-1.0905\n",
      "-0.9465\n",
      "-1.0288\n",
      "-1.1619\n",
      "-0.9461\n",
      "-0.7208\n",
      "-1.0627\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 0 [200/393 (50%)]\tLoss: 1.117814\n",
      "---------------------------------------- 21\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9852\n",
      "-1.0245\n",
      "-1.1624\n",
      "-0.9385\n",
      "-0.9344\n",
      "-0.9080\n",
      "-0.7696\n",
      "-0.8207\n",
      "-0.5263\n",
      "-0.6384\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 22\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7303\n",
      "-0.6208\n",
      "-0.4331\n",
      "-0.9180\n",
      "-0.6904\n",
      "-0.8024\n",
      "-0.9295\n",
      "-0.6510\n",
      "-1.1583\n",
      "-1.1535\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 23\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2027\n",
      "-1.0052\n",
      "-1.0039\n",
      "-1.0358\n",
      "-0.2021\n",
      "-1.0117\n",
      "-0.7571\n",
      "-0.7396\n",
      "-0.8108\n",
      "-1.0862\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 24\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.8621\n",
      "-0.5811\n",
      "-0.7781\n",
      "-0.5150\n",
      "-0.7518\n",
      "-1.0503\n",
      "-0.8138\n",
      "-0.9907\n",
      "-1.0588\n",
      "-0.4782\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 25\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7547\n",
      "-0.7895\n",
      "-0.8777\n",
      "-1.0643\n",
      "-0.7450\n",
      "-0.7600\n",
      "-0.5143\n",
      "-0.9273\n",
      "-0.7306\n",
      "-0.5168\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 1\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 26\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0232\n",
      "-0.5694\n",
      "-0.7016\n",
      "-1.0311\n",
      "-0.8267\n",
      "-0.8098\n",
      "-0.6158\n",
      "-0.9029\n",
      "-0.5755\n",
      "-0.8826\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 27\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9093\n",
      "-1.0852\n",
      "-1.1600\n",
      "-0.5516\n",
      "-0.7594\n",
      "-1.1524\n",
      "-1.0884\n",
      "-1.1501\n",
      "-0.9165\n",
      "-1.1681\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 28\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0525\n",
      "-0.7050\n",
      "-1.1160\n",
      "-0.6579\n",
      "-1.1557\n",
      "-0.9496\n",
      "-1.1472\n",
      "-0.9583\n",
      "-1.2588\n",
      "-1.2243\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 29\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.8569\n",
      "-0.7654\n",
      "-1.0818\n",
      "-1.0878\n",
      "-1.2012\n",
      "-1.1633\n",
      "-0.7131\n",
      "-0.5581\n",
      "-1.2141\n",
      "-1.2035\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 30\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1835\n",
      "-1.0056\n",
      "-1.1829\n",
      "-0.9603\n",
      "-1.1757\n",
      "-0.7314\n",
      "-1.1567\n",
      "-1.2509\n",
      "-1.1648\n",
      "-1.2800\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 1\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 0 [300/393 (75%)]\tLoss: 1.315837\n",
      "---------------------------------------- 31\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0395\n",
      "-1.2650\n",
      "-0.9709\n",
      "-1.2575\n",
      "-1.0996\n",
      "-1.2212\n",
      "-1.0990\n",
      "-0.8032\n",
      "-1.2491\n",
      "-0.8193\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 32\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0947\n",
      "-1.1112\n",
      "-1.1199\n",
      "-1.1874\n",
      "-1.2545\n",
      "-1.2353\n",
      "-1.2711\n",
      "-1.2134\n",
      "-1.2339\n",
      "-1.1634\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 33\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2531\n",
      "-1.2491\n",
      "-1.2407\n",
      "-1.2434\n",
      "-1.2235\n",
      "-1.2404\n",
      "-1.2264\n",
      "-1.2367\n",
      "-1.2415\n",
      "-1.2468\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 34\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2629\n",
      "-1.2681\n",
      "-1.2530\n",
      "-1.2146\n",
      "-1.2566\n",
      "-1.2236\n",
      "-1.2369\n",
      "-1.2554\n",
      "-1.2236\n",
      "-1.2340\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 35\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2564\n",
      "-1.2468\n",
      "-1.2141\n",
      "-1.2489\n",
      "-1.2385\n",
      "-1.2255\n",
      "-1.2117\n",
      "-1.2484\n",
      "-1.2464\n",
      "-1.2453\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 36\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2428\n",
      "-1.2457\n",
      "-1.2370\n",
      "-1.2348\n",
      "-1.2455\n",
      "-1.2022\n",
      "-1.2398\n",
      "-1.2405\n",
      "-1.2249\n",
      "-1.2447\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 37\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_max= (Variable containing:\n",
      "-1.1764\n",
      "-1.2272\n",
      "-1.2172\n",
      "-1.2155\n",
      "-1.2298\n",
      "-1.2392\n",
      "-1.2455\n",
      "-1.2157\n",
      "-1.2257\n",
      "-1.2179\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 38\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2045\n",
      "-1.2036\n",
      "-1.2284\n",
      "-1.2284\n",
      "-1.2006\n",
      "-1.2143\n",
      "-1.2168\n",
      "-1.2311\n",
      "-1.2037\n",
      "-1.2025\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "---------------------------------------- 39\n",
      "torch.Size([3, 3, 100, 100]) torch.Size([3])\n",
      "data= torch.Size([3, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2245\n",
      "-1.1851\n",
      "-1.2065\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 3]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 3]\n",
      " <class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:87",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d42952e28cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ajout de la constante de temps t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-d42952e28cb8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set: Final Accuracy: {:.3f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print que le pourcentage de rÃ©ussite final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-d42952e28cb8>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:87"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Training settings\n",
    "cuda = False\n",
    "torch.manual_seed(42)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('dataset',\n",
    "                                        transforms.Compose([\n",
    "                                        transforms.CenterCrop(100),\n",
    "                                        transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                        ])) \n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "test_loader= torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(500, args.dimension)# args.dimension prend la valeur default de l'argument dimension.\n",
    "        self.fc2 = nn.Linear(args.dimension, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 4))        \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 4))       \n",
    "        x = x.view(-1, 500)        \n",
    "        x = F.relu(self.fc1(x))        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#.cuda()#\n",
    "criterion = F.nll_loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#,0):\n",
    "        print(40*'-', batch_idx)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target) #[batch_idx].unsqueeze(0)\n",
    "        print(data.size(), target.size())\n",
    "              \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)#\n",
    "        output_max=torch.max(output,1)\n",
    "        print('data=',data.shape)\n",
    "        print ('output_max=',output_max)\n",
    "        \n",
    "        #print ('indent=',indent,type(indent))\n",
    "        print ('target=',target,type(target))\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        \n",
    "        loss = criterion(output, target-1)#\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.log_interval>0: # rajout de la commande pour pouvoir print ou non les diffÃ©rents epoch ou juste le rÃ©sultat\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if args.log_interval>0: print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def protocol():\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "    return test()\n",
    "\n",
    "def main():\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        Accuracy = test()\n",
    "    print('Test set: Final Accuracy: {:.3f}%'.format(Accuracy*100)) # print que le pourcentage de rÃ©ussite final\n",
    "    \n",
    "    \n",
    "t0 = time.time () # ajout de la constante de temps t0\n",
    "\n",
    "main()\n",
    "\n",
    "t1 = time.time () # ajout de la constante de temps t1\n",
    "\n",
    "print (\"Le programme a mis\",t1-t0, \"secondes Ã  s'exÃ©cuter.\") #compare t1 et t0, connaitre le temps d'execution du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0053\n",
      "-1.1620\n",
      "-0.9536\n",
      "-1.1968\n",
      "-1.1602\n",
      "-1.1837\n",
      "-1.2002\n",
      "-1.3235\n",
      "-0.9458\n",
      "-0.9863\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3216\n",
      "-1.2141\n",
      "-1.1857\n",
      "-0.9686\n",
      "-1.0989\n",
      "-1.0328\n",
      "-1.3275\n",
      "-1.2454\n",
      "-1.2697\n",
      "-1.2246\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 1\n",
      " 4\n",
      " 3\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 3\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1367\n",
      "-0.7521\n",
      "-0.8206\n",
      "-1.2430\n",
      "-1.2639\n",
      "-0.8447\n",
      "-1.2403\n",
      "-1.0528\n",
      "-0.9976\n",
      "-0.9627\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1458\n",
      "-1.3314\n",
      "-0.9129\n",
      "-1.0649\n",
      "-1.1555\n",
      "-1.2224\n",
      "-1.0796\n",
      "-1.1827\n",
      "-1.1212\n",
      "-0.9454\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2478\n",
      "-1.1563\n",
      "-1.3016\n",
      "-0.9631\n",
      "-1.1166\n",
      "-1.3016\n",
      "-1.2156\n",
      "-1.0595\n",
      "-0.9922\n",
      "-1.0713\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0129\n",
      "-1.1493\n",
      "-1.2918\n",
      "-1.2020\n",
      "-1.2426\n",
      "-1.1852\n",
      "-1.0055\n",
      "-1.0519\n",
      "-0.7429\n",
      "-1.1918\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 1\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3116\n",
      "-1.0580\n",
      "-0.8999\n",
      "-1.2180\n",
      "-1.0854\n",
      "-0.8386\n",
      "-1.3207\n",
      "-1.2472\n",
      "-0.6869\n",
      "-1.1744\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1695\n",
      "-1.0929\n",
      "-0.8522\n",
      "-1.0021\n",
      "-1.0761\n",
      "-1.1466\n",
      "-1.2625\n",
      "-1.1359\n",
      "-1.1951\n",
      "-1.2382\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3414\n",
      "-1.0868\n",
      "-1.2631\n",
      "-1.0735\n",
      "-1.1488\n",
      "-1.3106\n",
      "-1.0335\n",
      "-1.0694\n",
      "-1.1903\n",
      "-1.1598\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9871\n",
      "-1.3429\n",
      "-1.1596\n",
      "-1.1921\n",
      "-1.2511\n",
      "-1.2142\n",
      "-1.1804\n",
      "-0.8577\n",
      "-1.1778\n",
      "-1.3007\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0339\n",
      "-1.2471\n",
      "-1.0574\n",
      "-1.1591\n",
      "-1.1631\n",
      "-1.0803\n",
      "-1.0311\n",
      "-0.9858\n",
      "-1.0881\n",
      "-0.9690\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2545\n",
      "-0.9852\n",
      "-1.1570\n",
      "-1.2128\n",
      "-1.1818\n",
      "-1.0642\n",
      "-1.1666\n",
      "-1.1597\n",
      "-0.9477\n",
      "-1.0764\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.8434\n",
      "-1.0542\n",
      "-0.9607\n",
      "-1.0792\n",
      "-0.9534\n",
      "-1.1300\n",
      "-1.0992\n",
      "-1.1047\n",
      "-1.1642\n",
      "-1.1364\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7632\n",
      "-1.3244\n",
      "-1.2160\n",
      "-1.0439\n",
      "-0.8513\n",
      "-0.7619\n",
      "-1.0582\n",
      "-0.9314\n",
      "-1.0526\n",
      "-1.0204\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1000\n",
      "-1.2492\n",
      "-0.7905\n",
      "-0.8512\n",
      "-1.0970\n",
      "-1.0766\n",
      "-0.8871\n",
      "-1.0443\n",
      "-0.9962\n",
      "-1.2109\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1761\n",
      "-1.0989\n",
      "-0.9982\n",
      "-1.1920\n",
      "-1.2042\n",
      "-1.1522\n",
      "-1.3141\n",
      "-1.2014\n",
      "-1.2485\n",
      "-1.1071\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0324\n",
      "-1.1719\n",
      "-1.0691\n",
      "-0.8256\n",
      "-1.1937\n",
      "-1.3095\n",
      "-1.3027\n",
      "-1.0424\n",
      "-1.2643\n",
      "-1.2677\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2672\n",
      "-1.0504\n",
      "-1.0147\n",
      "-0.7198\n",
      "-1.0772\n",
      "-1.0782\n",
      "-1.3268\n",
      "-1.0239\n",
      "-0.9651\n",
      "-1.0514\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1288\n",
      "-1.1805\n",
      "-1.3624\n",
      "-1.1562\n",
      "-1.0956\n",
      "-1.2715\n",
      "-0.8919\n",
      "-1.3113\n",
      "-1.2043\n",
      "-1.2358\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1881\n",
      "-0.8000\n",
      "-1.0366\n",
      "-0.9616\n",
      "-1.0304\n",
      "-1.2681\n",
      "-0.9785\n",
      "-1.0737\n",
      "-0.9542\n",
      "-1.2685\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1749\n",
      "-1.1249\n",
      "-0.7271\n",
      "-1.3263\n",
      "-1.0078\n",
      "-1.1427\n",
      "-1.2256\n",
      "-1.1794\n",
      "-1.3254\n",
      "-1.0698\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2332\n",
      "-1.2679\n",
      "-0.9434\n",
      "-0.9751\n",
      "-1.1341\n",
      "-1.0943\n",
      "-1.3070\n",
      "-1.1387\n",
      "-1.2073\n",
      "-1.0084\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1997\n",
      "-1.1346\n",
      "-1.2410\n",
      "-0.9823\n",
      "-1.0360\n",
      "-1.2474\n",
      "-1.2536\n",
      "-1.2802\n",
      "-1.1997\n",
      "-1.3465\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2831\n",
      "-1.3392\n",
      "-1.1085\n",
      "-1.1872\n",
      "-1.1944\n",
      "-1.0212\n",
      "-1.1785\n",
      "-1.0929\n",
      "-0.9952\n",
      "-1.2036\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1904\n",
      "-1.1768\n",
      "-1.3549\n",
      "-1.1196\n",
      "-0.8733\n",
      "-1.1773\n",
      "-1.1814\n",
      "-1.1763\n",
      "-0.9459\n",
      "-1.0735\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3304\n",
      "-1.2612\n",
      "-0.9941\n",
      "-1.1822\n",
      "-1.1915\n",
      "-1.2484\n",
      "-1.1160\n",
      "-1.2111\n",
      "-1.3202\n",
      "-1.2197\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.8451\n",
      "-1.0004\n",
      "-1.1850\n",
      "-1.0853\n",
      "-0.7741\n",
      "-1.3399\n",
      "-1.2092\n",
      "-1.0149\n",
      "-1.1885\n",
      "-1.3491\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0649\n",
      "-1.1278\n",
      "-1.1734\n",
      "-1.2578\n",
      "-1.1709\n",
      "-1.0966\n",
      "-0.8512\n",
      "-1.1630\n",
      "-1.3278\n",
      "-1.1396\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0638\n",
      "-1.2078\n",
      "-1.1606\n",
      "-0.9600\n",
      "-1.1093\n",
      "-1.2653\n",
      "-1.0110\n",
      "-1.1305\n",
      "-1.3105\n",
      "-1.1939\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2229\n",
      "-1.0122\n",
      "-1.1878\n",
      "-1.1617\n",
      "-1.1187\n",
      "-0.8195\n",
      "-1.1492\n",
      "-1.0953\n",
      "-0.8956\n",
      "-0.8041\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.0927\n",
      "-1.2750\n",
      "-1.0641\n",
      "-1.3149\n",
      "-0.8128\n",
      "-1.0967\n",
      "-1.1088\n",
      "-1.1793\n",
      "-1.1072\n",
      "-0.9782\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1269\n",
      "-1.3086\n",
      "-1.2713\n",
      "-1.2074\n",
      "-1.1133\n",
      "-0.8871\n",
      "-0.5957\n",
      "-1.1787\n",
      "-1.0798\n",
      "-1.2904\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7430\n",
      "-1.0917\n",
      "-1.1460\n",
      "-1.1921\n",
      "-0.9414\n",
      "-0.9531\n",
      "-1.1249\n",
      "-1.1461\n",
      "-1.2360\n",
      "-0.8978\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.7020\n",
      "-1.3537\n",
      "-1.0361\n",
      "-0.9837\n",
      "-1.2651\n",
      "-1.3335\n",
      "-1.1716\n",
      "-0.9647\n",
      "-0.8789\n",
      "-1.2786\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2933\n",
      "-1.2820\n",
      "-0.8229\n",
      "-1.0840\n",
      "-1.0302\n",
      "-1.2161\n",
      "-1.1667\n",
      "-1.1453\n",
      "-1.1491\n",
      "-0.8071\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 3\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9537\n",
      "-0.8576\n",
      "-1.2260\n",
      "-1.1400\n",
      "-1.3308\n",
      "-1.2088\n",
      "-1.0019\n",
      "-1.1949\n",
      "-1.2941\n",
      "-0.9091\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.1580\n",
      "-1.2677\n",
      "-1.3011\n",
      "-1.0311\n",
      "-0.9157\n",
      "-0.8713\n",
      "-1.1153\n",
      "-1.2214\n",
      "-0.9698\n",
      "-0.9716\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-0.9999\n",
      "-1.2978\n",
      "-1.1931\n",
      "-1.1058\n",
      "-0.9344\n",
      "-1.3222\n",
      "-0.9416\n",
      "-1.0575\n",
      "-0.9957\n",
      "-1.1067\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 4\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([10, 3, 100, 100]) torch.Size([10])\n",
      "x= torch.Size([10, 3, 100, 100])\n",
      "x1= torch.Size([10, 10, 24, 24])\n",
      "x2= torch.Size([10, 20, 5, 5])\n",
      "x3= torch.Size([10, 500])\n",
      "x4= torch.Size([10, 120])\n",
      "x5= torch.Size([10, 120])\n",
      "x6= torch.Size([10, 4])\n",
      "data= torch.Size([10, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.3112\n",
      "-1.1727\n",
      "-0.9957\n",
      "-1.2549\n",
      "-1.2756\n",
      "-0.7933\n",
      "-1.2283\n",
      "-1.1947\n",
      "-1.2315\n",
      "-1.2640\n",
      "[torch.FloatTensor of size 10]\n",
      ", Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 10]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 10]\n",
      " <class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([3, 3, 100, 100]) torch.Size([3])\n",
      "x= torch.Size([3, 3, 100, 100])\n",
      "x1= torch.Size([3, 10, 24, 24])\n",
      "x2= torch.Size([3, 20, 5, 5])\n",
      "x3= torch.Size([3, 500])\n",
      "x4= torch.Size([3, 120])\n",
      "x5= torch.Size([3, 120])\n",
      "x6= torch.Size([3, 4])\n",
      "data= torch.Size([3, 3, 100, 100])\n",
      "output_max= (Variable containing:\n",
      "-1.2185\n",
      "-1.3485\n",
      "-0.8171\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 3]\n",
      ")\n",
      "target= Variable containing:\n",
      " 3\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 3]\n",
      " <class 'torch.autograd.variable.Variable'>\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):#,0):\n",
    "    if args.cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data), Variable(target) #[batch_idx].unsqueeze(0)\n",
    "    print(data.size(), target.size())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)#\n",
    "    output_max=torch.max(output,1)\n",
    "    print('data=',data.shape)\n",
    "    print ('output_max=',output_max)\n",
    "\n",
    "    #print ('indent=',indent,type(indent))\n",
    "    print ('target=',target,type(target))\n",
    "    #loss = F.nll_loss(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.4299 -1.2185 -1.3794 -1.5452\n",
       " -1.3590 -1.3485 -1.4205 -1.4195\n",
       " -1.8727 -0.8171 -1.2753 -2.0776\n",
       " [torch.FloatTensor of size 3x4], (Variable containing:\n",
       "  -1.2185\n",
       "  -1.3485\n",
       "  -0.8171\n",
       "  [torch.FloatTensor of size 3], Variable containing:\n",
       "   1\n",
       "   1\n",
       "   1\n",
       "  [torch.LongTensor of size 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, output_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.2185\n",
       " -1.3485\n",
       " -0.8171\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.LongTensor of size 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:87",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3cc4808439a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:87"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3\n",
       " 2\n",
       " 4\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 1\n",
       " 3\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run mnist.py --log-interval 0 --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Training settings\n",
    "\n",
    "print ('cuda?', torch.cuda.is_available())\n",
    "torch.manual_seed(44)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=10, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=10, shuffle=True, **kwargs)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)# args.dimension prend la valeur default de l'argument dimension.\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.log_interval>0: # rajout de la commande pour pouvoir print ou non les diffÃ©rents epoch ou juste le rÃ©sultat\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if args.log_interval>0: print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def protocol():\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "    return test()\n",
    "\n",
    "def main():\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "        Accuracy = test()\n",
    "    print('Test set: Final Accuracy: {:.3f}%'.format(Accuracy*100)) # print que le pourcentage de rÃ©ussite final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? True\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.415856\n",
      "Train Epoch: 1 [100/60000 (0%)]\tLoss: 2.289357\n",
      "Train Epoch: 1 [200/60000 (0%)]\tLoss: 2.287842\n",
      "Train Epoch: 1 [300/60000 (0%)]\tLoss: 2.274595\n",
      "Train Epoch: 1 [400/60000 (1%)]\tLoss: 2.287816\n",
      "Train Epoch: 1 [500/60000 (1%)]\tLoss: 2.305919\n",
      "Train Epoch: 1 [600/60000 (1%)]\tLoss: 2.238723\n",
      "Train Epoch: 1 [700/60000 (1%)]\tLoss: 2.199195\n",
      "Train Epoch: 1 [800/60000 (1%)]\tLoss: 2.143682\n",
      "Train Epoch: 1 [900/60000 (2%)]\tLoss: 2.180805\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.194519\n",
      "Train Epoch: 1 [1100/60000 (2%)]\tLoss: 2.168604\n",
      "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 1.938203\n",
      "Train Epoch: 1 [1300/60000 (2%)]\tLoss: 1.988117\n",
      "Train Epoch: 1 [1400/60000 (2%)]\tLoss: 1.586117\n",
      "Train Epoch: 1 [1500/60000 (2%)]\tLoss: 1.949722\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 1.819917\n",
      "Train Epoch: 1 [1700/60000 (3%)]\tLoss: 1.387675\n",
      "Train Epoch: 1 [1800/60000 (3%)]\tLoss: 1.617591\n",
      "Train Epoch: 1 [1900/60000 (3%)]\tLoss: 1.592736\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.177632\n",
      "Train Epoch: 1 [2100/60000 (4%)]\tLoss: 1.720529\n",
      "Train Epoch: 1 [2200/60000 (4%)]\tLoss: 1.815817\n",
      "Train Epoch: 1 [2300/60000 (4%)]\tLoss: 1.529843\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 1.166252\n",
      "Train Epoch: 1 [2500/60000 (4%)]\tLoss: 1.664790\n",
      "Train Epoch: 1 [2600/60000 (4%)]\tLoss: 0.973519\n",
      "Train Epoch: 1 [2700/60000 (4%)]\tLoss: 1.561113\n",
      "Train Epoch: 1 [2800/60000 (5%)]\tLoss: 0.609989\n",
      "Train Epoch: 1 [2900/60000 (5%)]\tLoss: 1.506395\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 1.712516\n",
      "Train Epoch: 1 [3100/60000 (5%)]\tLoss: 1.236704\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.944222\n",
      "Train Epoch: 1 [3300/60000 (6%)]\tLoss: 1.157696\n",
      "Train Epoch: 1 [3400/60000 (6%)]\tLoss: 1.007730\n",
      "Train Epoch: 1 [3500/60000 (6%)]\tLoss: 1.412458\n",
      "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 1.656551\n",
      "Train Epoch: 1 [3700/60000 (6%)]\tLoss: 0.765167\n",
      "Train Epoch: 1 [3800/60000 (6%)]\tLoss: 0.831256\n",
      "Train Epoch: 1 [3900/60000 (6%)]\tLoss: 0.703269\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.598981\n",
      "Train Epoch: 1 [4100/60000 (7%)]\tLoss: 1.351118\n",
      "Train Epoch: 1 [4200/60000 (7%)]\tLoss: 1.413051\n",
      "Train Epoch: 1 [4300/60000 (7%)]\tLoss: 1.137060\n",
      "Train Epoch: 1 [4400/60000 (7%)]\tLoss: 1.007501\n",
      "Train Epoch: 1 [4500/60000 (8%)]\tLoss: 0.309756\n",
      "Train Epoch: 1 [4600/60000 (8%)]\tLoss: 0.627702\n",
      "Train Epoch: 1 [4700/60000 (8%)]\tLoss: 0.860156\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.535921\n",
      "Train Epoch: 1 [4900/60000 (8%)]\tLoss: 0.444396\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.673588\n",
      "Train Epoch: 1 [5100/60000 (8%)]\tLoss: 0.576178\n",
      "Train Epoch: 1 [5200/60000 (9%)]\tLoss: 1.955670\n",
      "Train Epoch: 1 [5300/60000 (9%)]\tLoss: 0.738427\n",
      "Train Epoch: 1 [5400/60000 (9%)]\tLoss: 0.414152\n",
      "Train Epoch: 1 [5500/60000 (9%)]\tLoss: 0.562245\n",
      "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 1.004666\n",
      "Train Epoch: 1 [5700/60000 (10%)]\tLoss: 1.315499\n",
      "Train Epoch: 1 [5800/60000 (10%)]\tLoss: 0.822651\n",
      "Train Epoch: 1 [5900/60000 (10%)]\tLoss: 0.562719\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.475141\n",
      "Train Epoch: 1 [6100/60000 (10%)]\tLoss: 0.494205\n",
      "Train Epoch: 1 [6200/60000 (10%)]\tLoss: 0.941266\n",
      "Train Epoch: 1 [6300/60000 (10%)]\tLoss: 0.432762\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.935526\n",
      "Train Epoch: 1 [6500/60000 (11%)]\tLoss: 0.454448\n",
      "Train Epoch: 1 [6600/60000 (11%)]\tLoss: 1.027130\n",
      "Train Epoch: 1 [6700/60000 (11%)]\tLoss: 0.536649\n",
      "Train Epoch: 1 [6800/60000 (11%)]\tLoss: 0.593189\n",
      "Train Epoch: 1 [6900/60000 (12%)]\tLoss: 0.386067\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.217625\n",
      "Train Epoch: 1 [7100/60000 (12%)]\tLoss: 0.469634\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.865695\n",
      "Train Epoch: 1 [7300/60000 (12%)]\tLoss: 0.883983\n",
      "Train Epoch: 1 [7400/60000 (12%)]\tLoss: 1.204902\n",
      "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 0.416635\n",
      "Train Epoch: 1 [7600/60000 (13%)]\tLoss: 0.307815\n",
      "Train Epoch: 1 [7700/60000 (13%)]\tLoss: 0.708597\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 0.348477\n",
      "Train Epoch: 1 [7900/60000 (13%)]\tLoss: 1.172035\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.348034\n",
      "Train Epoch: 1 [8100/60000 (14%)]\tLoss: 0.853719\n",
      "Train Epoch: 1 [8200/60000 (14%)]\tLoss: 1.005705\n",
      "Train Epoch: 1 [8300/60000 (14%)]\tLoss: 2.005745\n",
      "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 0.740408\n",
      "Train Epoch: 1 [8500/60000 (14%)]\tLoss: 0.830181\n",
      "Train Epoch: 1 [8600/60000 (14%)]\tLoss: 0.450456\n",
      "Train Epoch: 1 [8700/60000 (14%)]\tLoss: 0.935919\n",
      "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 1.473039\n",
      "Train Epoch: 1 [8900/60000 (15%)]\tLoss: 1.094900\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.982080\n",
      "Train Epoch: 1 [9100/60000 (15%)]\tLoss: 0.883014\n",
      "Train Epoch: 1 [9200/60000 (15%)]\tLoss: 1.038109\n",
      "Train Epoch: 1 [9300/60000 (16%)]\tLoss: 0.555167\n",
      "Train Epoch: 1 [9400/60000 (16%)]\tLoss: 0.279907\n",
      "Train Epoch: 1 [9500/60000 (16%)]\tLoss: 0.441213\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.495332\n",
      "Train Epoch: 1 [9700/60000 (16%)]\tLoss: 0.239000\n",
      "Train Epoch: 1 [9800/60000 (16%)]\tLoss: 0.475837\n",
      "Train Epoch: 1 [9900/60000 (16%)]\tLoss: 0.510925\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.295410\n",
      "Train Epoch: 1 [10100/60000 (17%)]\tLoss: 0.753984\n",
      "Train Epoch: 1 [10200/60000 (17%)]\tLoss: 0.598852\n",
      "Train Epoch: 1 [10300/60000 (17%)]\tLoss: 1.068831\n",
      "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.509042\n",
      "Train Epoch: 1 [10500/60000 (18%)]\tLoss: 1.036154\n",
      "Train Epoch: 1 [10600/60000 (18%)]\tLoss: 0.090533\n",
      "Train Epoch: 1 [10700/60000 (18%)]\tLoss: 0.588829\n",
      "Train Epoch: 1 [10800/60000 (18%)]\tLoss: 0.943180\n",
      "Train Epoch: 1 [10900/60000 (18%)]\tLoss: 0.458882\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.973711\n",
      "Train Epoch: 1 [11100/60000 (18%)]\tLoss: 0.213257\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.758732\n",
      "Train Epoch: 1 [11300/60000 (19%)]\tLoss: 0.696851\n",
      "Train Epoch: 1 [11400/60000 (19%)]\tLoss: 0.574318\n",
      "Train Epoch: 1 [11500/60000 (19%)]\tLoss: 0.376460\n",
      "Train Epoch: 1 [11600/60000 (19%)]\tLoss: 0.464075\n",
      "Train Epoch: 1 [11700/60000 (20%)]\tLoss: 0.335401\n",
      "Train Epoch: 1 [11800/60000 (20%)]\tLoss: 0.559089\n",
      "Train Epoch: 1 [11900/60000 (20%)]\tLoss: 1.960758\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.999927\n",
      "Train Epoch: 1 [12100/60000 (20%)]\tLoss: 0.285766\n",
      "Train Epoch: 1 [12200/60000 (20%)]\tLoss: 0.734378\n",
      "Train Epoch: 1 [12300/60000 (20%)]\tLoss: 1.298298\n",
      "Train Epoch: 1 [12400/60000 (21%)]\tLoss: 1.168550\n",
      "Train Epoch: 1 [12500/60000 (21%)]\tLoss: 0.808638\n",
      "Train Epoch: 1 [12600/60000 (21%)]\tLoss: 0.617339\n",
      "Train Epoch: 1 [12700/60000 (21%)]\tLoss: 0.458600\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.627053\n",
      "Train Epoch: 1 [12900/60000 (22%)]\tLoss: 0.792638\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.258622\n",
      "Train Epoch: 1 [13100/60000 (22%)]\tLoss: 0.729500\n",
      "Train Epoch: 1 [13200/60000 (22%)]\tLoss: 2.779693\n",
      "Train Epoch: 1 [13300/60000 (22%)]\tLoss: 0.490131\n",
      "Train Epoch: 1 [13400/60000 (22%)]\tLoss: 1.053215\n",
      "Train Epoch: 1 [13500/60000 (22%)]\tLoss: 0.268726\n",
      "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 0.575750\n",
      "Train Epoch: 1 [13700/60000 (23%)]\tLoss: 1.256881\n",
      "Train Epoch: 1 [13800/60000 (23%)]\tLoss: 0.885110\n",
      "Train Epoch: 1 [13900/60000 (23%)]\tLoss: 0.214352\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.588382\n",
      "Train Epoch: 1 [14100/60000 (24%)]\tLoss: 0.459107\n",
      "Train Epoch: 1 [14200/60000 (24%)]\tLoss: 0.663296\n",
      "Train Epoch: 1 [14300/60000 (24%)]\tLoss: 0.360315\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.721336\n",
      "Train Epoch: 1 [14500/60000 (24%)]\tLoss: 0.723919\n",
      "Train Epoch: 1 [14600/60000 (24%)]\tLoss: 0.438095\n",
      "Train Epoch: 1 [14700/60000 (24%)]\tLoss: 0.483181\n",
      "Train Epoch: 1 [14800/60000 (25%)]\tLoss: 0.150174\n",
      "Train Epoch: 1 [14900/60000 (25%)]\tLoss: 0.385833\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.176180\n",
      "Train Epoch: 1 [15100/60000 (25%)]\tLoss: 0.893819\n",
      "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 0.121583\n",
      "Train Epoch: 1 [15300/60000 (26%)]\tLoss: 0.516826\n",
      "Train Epoch: 1 [15400/60000 (26%)]\tLoss: 0.263621\n",
      "Train Epoch: 1 [15500/60000 (26%)]\tLoss: 0.944031\n",
      "Train Epoch: 1 [15600/60000 (26%)]\tLoss: 0.523007\n",
      "Train Epoch: 1 [15700/60000 (26%)]\tLoss: 0.932526\n",
      "Train Epoch: 1 [15800/60000 (26%)]\tLoss: 0.229932\n",
      "Train Epoch: 1 [15900/60000 (26%)]\tLoss: 0.368049\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.577214\n",
      "Train Epoch: 1 [16100/60000 (27%)]\tLoss: 0.402070\n",
      "Train Epoch: 1 [16200/60000 (27%)]\tLoss: 0.252002\n",
      "Train Epoch: 1 [16300/60000 (27%)]\tLoss: 0.372276\n",
      "Train Epoch: 1 [16400/60000 (27%)]\tLoss: 0.719811\n",
      "Train Epoch: 1 [16500/60000 (28%)]\tLoss: 0.797585\n",
      "Train Epoch: 1 [16600/60000 (28%)]\tLoss: 0.998643\n",
      "Train Epoch: 1 [16700/60000 (28%)]\tLoss: 0.834650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 0.413692\n",
      "Train Epoch: 1 [16900/60000 (28%)]\tLoss: 0.351050\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.457967\n",
      "Train Epoch: 1 [17100/60000 (28%)]\tLoss: 0.267647\n",
      "Train Epoch: 1 [17200/60000 (29%)]\tLoss: 0.635248\n",
      "Train Epoch: 1 [17300/60000 (29%)]\tLoss: 0.215838\n",
      "Train Epoch: 1 [17400/60000 (29%)]\tLoss: 0.544601\n",
      "Train Epoch: 1 [17500/60000 (29%)]\tLoss: 1.269762\n",
      "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.923326\n",
      "Train Epoch: 1 [17700/60000 (30%)]\tLoss: 0.323928\n",
      "Train Epoch: 1 [17800/60000 (30%)]\tLoss: 0.683488\n",
      "Train Epoch: 1 [17900/60000 (30%)]\tLoss: 0.215470\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.419810\n",
      "Train Epoch: 1 [18100/60000 (30%)]\tLoss: 0.992294\n",
      "Train Epoch: 1 [18200/60000 (30%)]\tLoss: 0.414186\n",
      "Train Epoch: 1 [18300/60000 (30%)]\tLoss: 0.536497\n",
      "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 0.557489\n",
      "Train Epoch: 1 [18500/60000 (31%)]\tLoss: 0.550288\n",
      "Train Epoch: 1 [18600/60000 (31%)]\tLoss: 0.148705\n",
      "Train Epoch: 1 [18700/60000 (31%)]\tLoss: 0.258532\n",
      "Train Epoch: 1 [18800/60000 (31%)]\tLoss: 0.075607\n",
      "Train Epoch: 1 [18900/60000 (32%)]\tLoss: 0.345766\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.496812\n",
      "Train Epoch: 1 [19100/60000 (32%)]\tLoss: 0.258950\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.122677\n",
      "Train Epoch: 1 [19300/60000 (32%)]\tLoss: 0.315087\n",
      "Train Epoch: 1 [19400/60000 (32%)]\tLoss: 1.658852\n",
      "Train Epoch: 1 [19500/60000 (32%)]\tLoss: 0.412280\n",
      "Train Epoch: 1 [19600/60000 (33%)]\tLoss: 0.210950\n",
      "Train Epoch: 1 [19700/60000 (33%)]\tLoss: 0.120694\n",
      "Train Epoch: 1 [19800/60000 (33%)]\tLoss: 1.167190\n",
      "Train Epoch: 1 [19900/60000 (33%)]\tLoss: 0.346346\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.363182\n",
      "Train Epoch: 1 [20100/60000 (34%)]\tLoss: 0.212593\n",
      "Train Epoch: 1 [20200/60000 (34%)]\tLoss: 0.523079\n",
      "Train Epoch: 1 [20300/60000 (34%)]\tLoss: 0.656122\n",
      "Train Epoch: 1 [20400/60000 (34%)]\tLoss: 0.498541\n",
      "Train Epoch: 1 [20500/60000 (34%)]\tLoss: 1.026650\n",
      "Train Epoch: 1 [20600/60000 (34%)]\tLoss: 0.268423\n",
      "Train Epoch: 1 [20700/60000 (34%)]\tLoss: 0.176688\n",
      "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.319506\n",
      "Train Epoch: 1 [20900/60000 (35%)]\tLoss: 0.282069\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.218412\n",
      "Train Epoch: 1 [21100/60000 (35%)]\tLoss: 0.616368\n",
      "Train Epoch: 1 [21200/60000 (35%)]\tLoss: 0.242844\n",
      "Train Epoch: 1 [21300/60000 (36%)]\tLoss: 0.335285\n",
      "Train Epoch: 1 [21400/60000 (36%)]\tLoss: 0.310285\n",
      "Train Epoch: 1 [21500/60000 (36%)]\tLoss: 0.681946\n",
      "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 0.186718\n",
      "Train Epoch: 1 [21700/60000 (36%)]\tLoss: 0.526783\n",
      "Train Epoch: 1 [21800/60000 (36%)]\tLoss: 0.444144\n",
      "Train Epoch: 1 [21900/60000 (36%)]\tLoss: 0.328154\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.664421\n",
      "Train Epoch: 1 [22100/60000 (37%)]\tLoss: 0.261243\n",
      "Train Epoch: 1 [22200/60000 (37%)]\tLoss: 0.598946\n",
      "Train Epoch: 1 [22300/60000 (37%)]\tLoss: 0.399924\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.153441\n",
      "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 0.088278\n",
      "Train Epoch: 1 [22600/60000 (38%)]\tLoss: 0.124752\n",
      "Train Epoch: 1 [22700/60000 (38%)]\tLoss: 0.246471\n",
      "Train Epoch: 1 [22800/60000 (38%)]\tLoss: 1.055548\n",
      "Train Epoch: 1 [22900/60000 (38%)]\tLoss: 1.264613\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.072377\n",
      "Train Epoch: 1 [23100/60000 (38%)]\tLoss: 0.178838\n",
      "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 0.679389\n",
      "Train Epoch: 1 [23300/60000 (39%)]\tLoss: 0.124144\n",
      "Train Epoch: 1 [23400/60000 (39%)]\tLoss: 0.103067\n",
      "Train Epoch: 1 [23500/60000 (39%)]\tLoss: 0.562073\n",
      "Train Epoch: 1 [23600/60000 (39%)]\tLoss: 0.552659\n",
      "Train Epoch: 1 [23700/60000 (40%)]\tLoss: 1.079756\n",
      "Train Epoch: 1 [23800/60000 (40%)]\tLoss: 0.368144\n",
      "Train Epoch: 1 [23900/60000 (40%)]\tLoss: 0.048609\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.378120\n",
      "Train Epoch: 1 [24100/60000 (40%)]\tLoss: 0.088659\n",
      "Train Epoch: 1 [24200/60000 (40%)]\tLoss: 0.066758\n",
      "Train Epoch: 1 [24300/60000 (40%)]\tLoss: 1.192833\n",
      "Train Epoch: 1 [24400/60000 (41%)]\tLoss: 0.243928\n",
      "Train Epoch: 1 [24500/60000 (41%)]\tLoss: 0.301833\n",
      "Train Epoch: 1 [24600/60000 (41%)]\tLoss: 0.523758\n",
      "Train Epoch: 1 [24700/60000 (41%)]\tLoss: 0.218916\n",
      "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 0.596863\n",
      "Train Epoch: 1 [24900/60000 (42%)]\tLoss: 0.201751\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.346536\n",
      "Train Epoch: 1 [25100/60000 (42%)]\tLoss: 0.135070\n",
      "Train Epoch: 1 [25200/60000 (42%)]\tLoss: 0.281654\n",
      "Train Epoch: 1 [25300/60000 (42%)]\tLoss: 0.764352\n",
      "Train Epoch: 1 [25400/60000 (42%)]\tLoss: 0.239534\n",
      "Train Epoch: 1 [25500/60000 (42%)]\tLoss: 0.170834\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.133636\n",
      "Train Epoch: 1 [25700/60000 (43%)]\tLoss: 0.398693\n",
      "Train Epoch: 1 [25800/60000 (43%)]\tLoss: 0.359556\n",
      "Train Epoch: 1 [25900/60000 (43%)]\tLoss: 0.716668\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.554444\n",
      "Train Epoch: 1 [26100/60000 (44%)]\tLoss: 1.190539\n",
      "Train Epoch: 1 [26200/60000 (44%)]\tLoss: 0.144611\n",
      "Train Epoch: 1 [26300/60000 (44%)]\tLoss: 0.523845\n",
      "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 0.229756\n",
      "Train Epoch: 1 [26500/60000 (44%)]\tLoss: 0.194804\n",
      "Train Epoch: 1 [26600/60000 (44%)]\tLoss: 0.315573\n",
      "Train Epoch: 1 [26700/60000 (44%)]\tLoss: 0.349860\n",
      "Train Epoch: 1 [26800/60000 (45%)]\tLoss: 0.151606\n",
      "Train Epoch: 1 [26900/60000 (45%)]\tLoss: 0.140343\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.842364\n",
      "Train Epoch: 1 [27100/60000 (45%)]\tLoss: 0.023964\n",
      "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.275623\n",
      "Train Epoch: 1 [27300/60000 (46%)]\tLoss: 0.516333\n",
      "Train Epoch: 1 [27400/60000 (46%)]\tLoss: 0.802875\n",
      "Train Epoch: 1 [27500/60000 (46%)]\tLoss: 0.013428\n",
      "Train Epoch: 1 [27600/60000 (46%)]\tLoss: 0.142296\n",
      "Train Epoch: 1 [27700/60000 (46%)]\tLoss: 0.426737\n",
      "Train Epoch: 1 [27800/60000 (46%)]\tLoss: 0.225427\n",
      "Train Epoch: 1 [27900/60000 (46%)]\tLoss: 1.108640\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.103556\n",
      "Train Epoch: 1 [28100/60000 (47%)]\tLoss: 0.430257\n",
      "Train Epoch: 1 [28200/60000 (47%)]\tLoss: 0.216349\n",
      "Train Epoch: 1 [28300/60000 (47%)]\tLoss: 0.742167\n",
      "Train Epoch: 1 [28400/60000 (47%)]\tLoss: 0.334701\n",
      "Train Epoch: 1 [28500/60000 (48%)]\tLoss: 1.147625\n",
      "Train Epoch: 1 [28600/60000 (48%)]\tLoss: 0.139727\n",
      "Train Epoch: 1 [28700/60000 (48%)]\tLoss: 0.337075\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.528477\n",
      "Train Epoch: 1 [28900/60000 (48%)]\tLoss: 0.238503\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.468626\n",
      "Train Epoch: 1 [29100/60000 (48%)]\tLoss: 0.674054\n",
      "Train Epoch: 1 [29200/60000 (49%)]\tLoss: 0.666148\n",
      "Train Epoch: 1 [29300/60000 (49%)]\tLoss: 0.661977\n",
      "Train Epoch: 1 [29400/60000 (49%)]\tLoss: 0.126071\n",
      "Train Epoch: 1 [29500/60000 (49%)]\tLoss: 0.091081\n",
      "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 0.561859\n",
      "Train Epoch: 1 [29700/60000 (50%)]\tLoss: 0.864005\n",
      "Train Epoch: 1 [29800/60000 (50%)]\tLoss: 0.199196\n",
      "Train Epoch: 1 [29900/60000 (50%)]\tLoss: 0.026738\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.198989\n",
      "Train Epoch: 1 [30100/60000 (50%)]\tLoss: 0.165792\n",
      "Train Epoch: 1 [30200/60000 (50%)]\tLoss: 0.271307\n",
      "Train Epoch: 1 [30300/60000 (50%)]\tLoss: 0.628831\n",
      "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 1.028420\n",
      "Train Epoch: 1 [30500/60000 (51%)]\tLoss: 0.128262\n",
      "Train Epoch: 1 [30600/60000 (51%)]\tLoss: 0.308031\n",
      "Train Epoch: 1 [30700/60000 (51%)]\tLoss: 0.211938\n",
      "Train Epoch: 1 [30800/60000 (51%)]\tLoss: 0.077406\n",
      "Train Epoch: 1 [30900/60000 (52%)]\tLoss: 0.203890\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.480607\n",
      "Train Epoch: 1 [31100/60000 (52%)]\tLoss: 0.853254\n",
      "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 0.910127\n",
      "Train Epoch: 1 [31300/60000 (52%)]\tLoss: 1.280182\n",
      "Train Epoch: 1 [31400/60000 (52%)]\tLoss: 0.293363\n",
      "Train Epoch: 1 [31500/60000 (52%)]\tLoss: 0.142950\n",
      "Train Epoch: 1 [31600/60000 (53%)]\tLoss: 0.348093\n",
      "Train Epoch: 1 [31700/60000 (53%)]\tLoss: 0.088143\n",
      "Train Epoch: 1 [31800/60000 (53%)]\tLoss: 0.297554\n",
      "Train Epoch: 1 [31900/60000 (53%)]\tLoss: 0.324411\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.264850\n",
      "Train Epoch: 1 [32100/60000 (54%)]\tLoss: 0.468273\n",
      "Train Epoch: 1 [32200/60000 (54%)]\tLoss: 0.315867\n",
      "Train Epoch: 1 [32300/60000 (54%)]\tLoss: 0.255064\n",
      "Train Epoch: 1 [32400/60000 (54%)]\tLoss: 0.218491\n",
      "Train Epoch: 1 [32500/60000 (54%)]\tLoss: 2.217667\n",
      "Train Epoch: 1 [32600/60000 (54%)]\tLoss: 0.327389\n",
      "Train Epoch: 1 [32700/60000 (54%)]\tLoss: 0.410966\n",
      "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 0.499364\n",
      "Train Epoch: 1 [32900/60000 (55%)]\tLoss: 0.032462\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.425830\n",
      "Train Epoch: 1 [33100/60000 (55%)]\tLoss: 0.287182\n",
      "Train Epoch: 1 [33200/60000 (55%)]\tLoss: 0.224042\n",
      "Train Epoch: 1 [33300/60000 (56%)]\tLoss: 0.361036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [33400/60000 (56%)]\tLoss: 0.558988\n",
      "Train Epoch: 1 [33500/60000 (56%)]\tLoss: 0.338025\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.111410\n",
      "Train Epoch: 1 [33700/60000 (56%)]\tLoss: 0.435465\n",
      "Train Epoch: 1 [33800/60000 (56%)]\tLoss: 0.232311\n",
      "Train Epoch: 1 [33900/60000 (56%)]\tLoss: 0.323663\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.132248\n",
      "Train Epoch: 1 [34100/60000 (57%)]\tLoss: 0.172165\n",
      "Train Epoch: 1 [34200/60000 (57%)]\tLoss: 0.252455\n",
      "Train Epoch: 1 [34300/60000 (57%)]\tLoss: 0.372268\n",
      "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 0.486066\n",
      "Train Epoch: 1 [34500/60000 (58%)]\tLoss: 0.428754\n",
      "Train Epoch: 1 [34600/60000 (58%)]\tLoss: 0.432736\n",
      "Train Epoch: 1 [34700/60000 (58%)]\tLoss: 0.170710\n",
      "Train Epoch: 1 [34800/60000 (58%)]\tLoss: 0.465786\n",
      "Train Epoch: 1 [34900/60000 (58%)]\tLoss: 0.629376\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.169195\n",
      "Train Epoch: 1 [35100/60000 (58%)]\tLoss: 0.267520\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.332796\n",
      "Train Epoch: 1 [35300/60000 (59%)]\tLoss: 0.552678\n",
      "Train Epoch: 1 [35400/60000 (59%)]\tLoss: 0.086185\n",
      "Train Epoch: 1 [35500/60000 (59%)]\tLoss: 0.143531\n",
      "Train Epoch: 1 [35600/60000 (59%)]\tLoss: 0.040487\n",
      "Train Epoch: 1 [35700/60000 (60%)]\tLoss: 0.689889\n",
      "Train Epoch: 1 [35800/60000 (60%)]\tLoss: 0.603996\n",
      "Train Epoch: 1 [35900/60000 (60%)]\tLoss: 0.517959\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.539076\n",
      "Train Epoch: 1 [36100/60000 (60%)]\tLoss: 0.090958\n",
      "Train Epoch: 1 [36200/60000 (60%)]\tLoss: 0.257233\n",
      "Train Epoch: 1 [36300/60000 (60%)]\tLoss: 0.168486\n",
      "Train Epoch: 1 [36400/60000 (61%)]\tLoss: 0.179517\n",
      "Train Epoch: 1 [36500/60000 (61%)]\tLoss: 0.196861\n",
      "Train Epoch: 1 [36600/60000 (61%)]\tLoss: 0.130998\n",
      "Train Epoch: 1 [36700/60000 (61%)]\tLoss: 0.244760\n",
      "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 1.003923\n",
      "Train Epoch: 1 [36900/60000 (62%)]\tLoss: 1.317202\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 1.612129\n",
      "Train Epoch: 1 [37100/60000 (62%)]\tLoss: 0.279825\n",
      "Train Epoch: 1 [37200/60000 (62%)]\tLoss: 0.498843\n",
      "Train Epoch: 1 [37300/60000 (62%)]\tLoss: 0.217631\n",
      "Train Epoch: 1 [37400/60000 (62%)]\tLoss: 0.599415\n",
      "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 0.303725\n",
      "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 0.043190\n",
      "Train Epoch: 1 [37700/60000 (63%)]\tLoss: 0.473164\n",
      "Train Epoch: 1 [37800/60000 (63%)]\tLoss: 0.258991\n",
      "Train Epoch: 1 [37900/60000 (63%)]\tLoss: 0.717882\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.615734\n",
      "Train Epoch: 1 [38100/60000 (64%)]\tLoss: 0.204239\n",
      "Train Epoch: 1 [38200/60000 (64%)]\tLoss: 0.152892\n",
      "Train Epoch: 1 [38300/60000 (64%)]\tLoss: 0.061935\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.515375\n",
      "Train Epoch: 1 [38500/60000 (64%)]\tLoss: 0.110611\n",
      "Train Epoch: 1 [38600/60000 (64%)]\tLoss: 0.510282\n",
      "Train Epoch: 1 [38700/60000 (64%)]\tLoss: 0.325111\n",
      "Train Epoch: 1 [38800/60000 (65%)]\tLoss: 0.525016\n",
      "Train Epoch: 1 [38900/60000 (65%)]\tLoss: 0.026111\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.925990\n",
      "Train Epoch: 1 [39100/60000 (65%)]\tLoss: 0.191622\n",
      "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 0.020639\n",
      "Train Epoch: 1 [39300/60000 (66%)]\tLoss: 0.225102\n",
      "Train Epoch: 1 [39400/60000 (66%)]\tLoss: 0.023668\n",
      "Train Epoch: 1 [39500/60000 (66%)]\tLoss: 0.516253\n",
      "Train Epoch: 1 [39600/60000 (66%)]\tLoss: 0.236677\n",
      "Train Epoch: 1 [39700/60000 (66%)]\tLoss: 0.828903\n",
      "Train Epoch: 1 [39800/60000 (66%)]\tLoss: 0.073006\n",
      "Train Epoch: 1 [39900/60000 (66%)]\tLoss: 0.544444\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.340191\n",
      "Train Epoch: 1 [40100/60000 (67%)]\tLoss: 0.416127\n",
      "Train Epoch: 1 [40200/60000 (67%)]\tLoss: 0.324684\n",
      "Train Epoch: 1 [40300/60000 (67%)]\tLoss: 0.316303\n",
      "Train Epoch: 1 [40400/60000 (67%)]\tLoss: 0.672964\n",
      "Train Epoch: 1 [40500/60000 (68%)]\tLoss: 0.704531\n",
      "Train Epoch: 1 [40600/60000 (68%)]\tLoss: 0.075133\n",
      "Train Epoch: 1 [40700/60000 (68%)]\tLoss: 0.552214\n",
      "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 0.113387\n",
      "Train Epoch: 1 [40900/60000 (68%)]\tLoss: 0.930492\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.081540\n",
      "Train Epoch: 1 [41100/60000 (68%)]\tLoss: 0.645827\n",
      "Train Epoch: 1 [41200/60000 (69%)]\tLoss: 0.098492\n",
      "Train Epoch: 1 [41300/60000 (69%)]\tLoss: 0.223162\n",
      "Train Epoch: 1 [41400/60000 (69%)]\tLoss: 0.300475\n",
      "Train Epoch: 1 [41500/60000 (69%)]\tLoss: 1.043376\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.439590\n",
      "Train Epoch: 1 [41700/60000 (70%)]\tLoss: 0.746078\n",
      "Train Epoch: 1 [41800/60000 (70%)]\tLoss: 0.036985\n",
      "Train Epoch: 1 [41900/60000 (70%)]\tLoss: 0.437034\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.249695\n",
      "Train Epoch: 1 [42100/60000 (70%)]\tLoss: 0.156765\n",
      "Train Epoch: 1 [42200/60000 (70%)]\tLoss: 0.369805\n",
      "Train Epoch: 1 [42300/60000 (70%)]\tLoss: 0.376635\n",
      "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 0.263091\n",
      "Train Epoch: 1 [42500/60000 (71%)]\tLoss: 0.119233\n",
      "Train Epoch: 1 [42600/60000 (71%)]\tLoss: 0.368061\n",
      "Train Epoch: 1 [42700/60000 (71%)]\tLoss: 0.477056\n",
      "Train Epoch: 1 [42800/60000 (71%)]\tLoss: 0.491069\n",
      "Train Epoch: 1 [42900/60000 (72%)]\tLoss: 0.065467\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.164562\n",
      "Train Epoch: 1 [43100/60000 (72%)]\tLoss: 0.442940\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.229518\n",
      "Train Epoch: 1 [43300/60000 (72%)]\tLoss: 0.088009\n",
      "Train Epoch: 1 [43400/60000 (72%)]\tLoss: 0.015043\n",
      "Train Epoch: 1 [43500/60000 (72%)]\tLoss: 0.094395\n",
      "Train Epoch: 1 [43600/60000 (73%)]\tLoss: 0.330412\n",
      "Train Epoch: 1 [43700/60000 (73%)]\tLoss: 0.081190\n",
      "Train Epoch: 1 [43800/60000 (73%)]\tLoss: 0.160983\n",
      "Train Epoch: 1 [43900/60000 (73%)]\tLoss: 0.077595\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.496062\n",
      "Train Epoch: 1 [44100/60000 (74%)]\tLoss: 0.243199\n",
      "Train Epoch: 1 [44200/60000 (74%)]\tLoss: 0.259936\n",
      "Train Epoch: 1 [44300/60000 (74%)]\tLoss: 0.143342\n",
      "Train Epoch: 1 [44400/60000 (74%)]\tLoss: 0.055074\n",
      "Train Epoch: 1 [44500/60000 (74%)]\tLoss: 1.046039\n",
      "Train Epoch: 1 [44600/60000 (74%)]\tLoss: 0.377599\n",
      "Train Epoch: 1 [44700/60000 (74%)]\tLoss: 0.191955\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.475036\n",
      "Train Epoch: 1 [44900/60000 (75%)]\tLoss: 0.551234\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.050064\n",
      "Train Epoch: 1 [45100/60000 (75%)]\tLoss: 0.251548\n",
      "Train Epoch: 1 [45200/60000 (75%)]\tLoss: 0.044939\n",
      "Train Epoch: 1 [45300/60000 (76%)]\tLoss: 0.545760\n",
      "Train Epoch: 1 [45400/60000 (76%)]\tLoss: 0.094249\n",
      "Train Epoch: 1 [45500/60000 (76%)]\tLoss: 0.052905\n",
      "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.320318\n",
      "Train Epoch: 1 [45700/60000 (76%)]\tLoss: 0.292293\n",
      "Train Epoch: 1 [45800/60000 (76%)]\tLoss: 0.129089\n",
      "Train Epoch: 1 [45900/60000 (76%)]\tLoss: 0.006796\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.487348\n",
      "Train Epoch: 1 [46100/60000 (77%)]\tLoss: 0.298002\n",
      "Train Epoch: 1 [46200/60000 (77%)]\tLoss: 0.009453\n",
      "Train Epoch: 1 [46300/60000 (77%)]\tLoss: 0.123273\n",
      "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.808634\n",
      "Train Epoch: 1 [46500/60000 (78%)]\tLoss: 0.937364\n",
      "Train Epoch: 1 [46600/60000 (78%)]\tLoss: 0.022938\n",
      "Train Epoch: 1 [46700/60000 (78%)]\tLoss: 0.087317\n",
      "Train Epoch: 1 [46800/60000 (78%)]\tLoss: 0.423099\n",
      "Train Epoch: 1 [46900/60000 (78%)]\tLoss: 0.052223\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.511938\n",
      "Train Epoch: 1 [47100/60000 (78%)]\tLoss: 0.640138\n",
      "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 0.166569\n",
      "Train Epoch: 1 [47300/60000 (79%)]\tLoss: 0.601593\n",
      "Train Epoch: 1 [47400/60000 (79%)]\tLoss: 0.923424\n",
      "Train Epoch: 1 [47500/60000 (79%)]\tLoss: 0.452647\n",
      "Train Epoch: 1 [47600/60000 (79%)]\tLoss: 0.131943\n",
      "Train Epoch: 1 [47700/60000 (80%)]\tLoss: 0.469777\n",
      "Train Epoch: 1 [47800/60000 (80%)]\tLoss: 0.392317\n",
      "Train Epoch: 1 [47900/60000 (80%)]\tLoss: 0.095016\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.147798\n",
      "Train Epoch: 1 [48100/60000 (80%)]\tLoss: 0.306738\n",
      "Train Epoch: 1 [48200/60000 (80%)]\tLoss: 0.259485\n",
      "Train Epoch: 1 [48300/60000 (80%)]\tLoss: 0.562129\n",
      "Train Epoch: 1 [48400/60000 (81%)]\tLoss: 0.236942\n",
      "Train Epoch: 1 [48500/60000 (81%)]\tLoss: 0.356890\n",
      "Train Epoch: 1 [48600/60000 (81%)]\tLoss: 0.647132\n",
      "Train Epoch: 1 [48700/60000 (81%)]\tLoss: 0.115107\n",
      "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 0.423641\n",
      "Train Epoch: 1 [48900/60000 (82%)]\tLoss: 0.038582\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.203648\n",
      "Train Epoch: 1 [49100/60000 (82%)]\tLoss: 0.154942\n",
      "Train Epoch: 1 [49200/60000 (82%)]\tLoss: 0.052883\n",
      "Train Epoch: 1 [49300/60000 (82%)]\tLoss: 0.301764\n",
      "Train Epoch: 1 [49400/60000 (82%)]\tLoss: 0.118990\n",
      "Train Epoch: 1 [49500/60000 (82%)]\tLoss: 0.193105\n",
      "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.318292\n",
      "Train Epoch: 1 [49700/60000 (83%)]\tLoss: 0.474814\n",
      "Train Epoch: 1 [49800/60000 (83%)]\tLoss: 0.362466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [49900/60000 (83%)]\tLoss: 0.322733\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.020118\n",
      "Train Epoch: 1 [50100/60000 (84%)]\tLoss: 0.036235\n",
      "Train Epoch: 1 [50200/60000 (84%)]\tLoss: 0.115878\n",
      "Train Epoch: 1 [50300/60000 (84%)]\tLoss: 0.045836\n",
      "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.141155\n",
      "Train Epoch: 1 [50500/60000 (84%)]\tLoss: 0.034315\n",
      "Train Epoch: 1 [50600/60000 (84%)]\tLoss: 0.394361\n",
      "Train Epoch: 1 [50700/60000 (84%)]\tLoss: 0.647950\n",
      "Train Epoch: 1 [50800/60000 (85%)]\tLoss: 0.156849\n",
      "Train Epoch: 1 [50900/60000 (85%)]\tLoss: 0.159053\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.124836\n",
      "Train Epoch: 1 [51100/60000 (85%)]\tLoss: 0.057172\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.459243\n",
      "Train Epoch: 1 [51300/60000 (86%)]\tLoss: 0.135976\n",
      "Train Epoch: 1 [51400/60000 (86%)]\tLoss: 0.111017\n",
      "Train Epoch: 1 [51500/60000 (86%)]\tLoss: 0.186561\n",
      "Train Epoch: 1 [51600/60000 (86%)]\tLoss: 0.155785\n",
      "Train Epoch: 1 [51700/60000 (86%)]\tLoss: 0.365653\n",
      "Train Epoch: 1 [51800/60000 (86%)]\tLoss: 0.285476\n",
      "Train Epoch: 1 [51900/60000 (86%)]\tLoss: 0.278290\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.973782\n",
      "Train Epoch: 1 [52100/60000 (87%)]\tLoss: 0.141408\n",
      "Train Epoch: 1 [52200/60000 (87%)]\tLoss: 0.183978\n",
      "Train Epoch: 1 [52300/60000 (87%)]\tLoss: 0.050032\n",
      "Train Epoch: 1 [52400/60000 (87%)]\tLoss: 0.026396\n",
      "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 0.073358\n",
      "Train Epoch: 1 [52600/60000 (88%)]\tLoss: 0.076963\n",
      "Train Epoch: 1 [52700/60000 (88%)]\tLoss: 0.330271\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.244194\n",
      "Train Epoch: 1 [52900/60000 (88%)]\tLoss: 0.362132\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.207003\n",
      "Train Epoch: 1 [53100/60000 (88%)]\tLoss: 0.290213\n",
      "Train Epoch: 1 [53200/60000 (89%)]\tLoss: 0.387760\n",
      "Train Epoch: 1 [53300/60000 (89%)]\tLoss: 1.129773\n",
      "Train Epoch: 1 [53400/60000 (89%)]\tLoss: 0.467623\n",
      "Train Epoch: 1 [53500/60000 (89%)]\tLoss: 0.647969\n",
      "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 0.332791\n",
      "Train Epoch: 1 [53700/60000 (90%)]\tLoss: 0.550944\n",
      "Train Epoch: 1 [53800/60000 (90%)]\tLoss: 0.342415\n",
      "Train Epoch: 1 [53900/60000 (90%)]\tLoss: 0.118186\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.123284\n",
      "Train Epoch: 1 [54100/60000 (90%)]\tLoss: 0.254864\n",
      "Train Epoch: 1 [54200/60000 (90%)]\tLoss: 0.282855\n",
      "Train Epoch: 1 [54300/60000 (90%)]\tLoss: 0.105497\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.158483\n",
      "Train Epoch: 1 [54500/60000 (91%)]\tLoss: 0.625780\n",
      "Train Epoch: 1 [54600/60000 (91%)]\tLoss: 0.167828\n",
      "Train Epoch: 1 [54700/60000 (91%)]\tLoss: 0.197517\n",
      "Train Epoch: 1 [54800/60000 (91%)]\tLoss: 0.485295\n",
      "Train Epoch: 1 [54900/60000 (92%)]\tLoss: 0.343527\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.171436\n",
      "Train Epoch: 1 [55100/60000 (92%)]\tLoss: 0.554996\n",
      "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.514965\n",
      "Train Epoch: 1 [55300/60000 (92%)]\tLoss: 0.317379\n",
      "Train Epoch: 1 [55400/60000 (92%)]\tLoss: 0.187321\n",
      "Train Epoch: 1 [55500/60000 (92%)]\tLoss: 0.148516\n",
      "Train Epoch: 1 [55600/60000 (93%)]\tLoss: 0.521515\n",
      "Train Epoch: 1 [55700/60000 (93%)]\tLoss: 0.542386\n",
      "Train Epoch: 1 [55800/60000 (93%)]\tLoss: 0.785386\n",
      "Train Epoch: 1 [55900/60000 (93%)]\tLoss: 0.042181\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.271786\n",
      "Train Epoch: 1 [56100/60000 (94%)]\tLoss: 0.142272\n",
      "Train Epoch: 1 [56200/60000 (94%)]\tLoss: 0.016978\n",
      "Train Epoch: 1 [56300/60000 (94%)]\tLoss: 0.683118\n",
      "Train Epoch: 1 [56400/60000 (94%)]\tLoss: 0.268714\n",
      "Train Epoch: 1 [56500/60000 (94%)]\tLoss: 0.243421\n",
      "Train Epoch: 1 [56600/60000 (94%)]\tLoss: 0.342507\n",
      "Train Epoch: 1 [56700/60000 (94%)]\tLoss: 0.066757\n",
      "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 0.078154\n",
      "Train Epoch: 1 [56900/60000 (95%)]\tLoss: 0.712091\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.093115\n",
      "Train Epoch: 1 [57100/60000 (95%)]\tLoss: 0.482257\n",
      "Train Epoch: 1 [57200/60000 (95%)]\tLoss: 0.240329\n",
      "Train Epoch: 1 [57300/60000 (96%)]\tLoss: 0.148122\n",
      "Train Epoch: 1 [57400/60000 (96%)]\tLoss: 0.053200\n",
      "Train Epoch: 1 [57500/60000 (96%)]\tLoss: 0.127278\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.332617\n",
      "Train Epoch: 1 [57700/60000 (96%)]\tLoss: 0.549412\n",
      "Train Epoch: 1 [57800/60000 (96%)]\tLoss: 0.271011\n",
      "Train Epoch: 1 [57900/60000 (96%)]\tLoss: 0.717932\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.336847\n",
      "Train Epoch: 1 [58100/60000 (97%)]\tLoss: 0.238091\n",
      "Train Epoch: 1 [58200/60000 (97%)]\tLoss: 0.066919\n",
      "Train Epoch: 1 [58300/60000 (97%)]\tLoss: 0.762435\n",
      "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 0.100635\n",
      "Train Epoch: 1 [58500/60000 (98%)]\tLoss: 0.085233\n",
      "Train Epoch: 1 [58600/60000 (98%)]\tLoss: 0.055478\n",
      "Train Epoch: 1 [58700/60000 (98%)]\tLoss: 0.030868\n",
      "Train Epoch: 1 [58800/60000 (98%)]\tLoss: 0.100944\n",
      "Train Epoch: 1 [58900/60000 (98%)]\tLoss: 0.148557\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.150085\n",
      "Train Epoch: 1 [59100/60000 (98%)]\tLoss: 0.400946\n",
      "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.012332\n",
      "Train Epoch: 1 [59300/60000 (99%)]\tLoss: 0.559327\n",
      "Train Epoch: 1 [59400/60000 (99%)]\tLoss: 0.296736\n",
      "Train Epoch: 1 [59500/60000 (99%)]\tLoss: 0.019276\n",
      "Train Epoch: 1 [59600/60000 (99%)]\tLoss: 0.080911\n",
      "Train Epoch: 1 [59700/60000 (100%)]\tLoss: 0.399008\n",
      "Train Epoch: 1 [59800/60000 (100%)]\tLoss: 0.069527\n",
      "Train Epoch: 1 [59900/60000 (100%)]\tLoss: 0.018471\n",
      "\n",
      "Test set: Average loss: 0.0891, Accuracy: 9727/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.336727\n",
      "Train Epoch: 2 [100/60000 (0%)]\tLoss: 0.845068\n",
      "Train Epoch: 2 [200/60000 (0%)]\tLoss: 0.027990\n",
      "Train Epoch: 2 [300/60000 (0%)]\tLoss: 0.162630\n",
      "Train Epoch: 2 [400/60000 (1%)]\tLoss: 0.023998\n",
      "Train Epoch: 2 [500/60000 (1%)]\tLoss: 0.048220\n",
      "Train Epoch: 2 [600/60000 (1%)]\tLoss: 0.007357\n",
      "Train Epoch: 2 [700/60000 (1%)]\tLoss: 0.077366\n",
      "Train Epoch: 2 [800/60000 (1%)]\tLoss: 1.244260\n",
      "Train Epoch: 2 [900/60000 (2%)]\tLoss: 0.079757\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.229113\n",
      "Train Epoch: 2 [1100/60000 (2%)]\tLoss: 0.318800\n",
      "Train Epoch: 2 [1200/60000 (2%)]\tLoss: 0.307580\n",
      "Train Epoch: 2 [1300/60000 (2%)]\tLoss: 0.861715\n",
      "Train Epoch: 2 [1400/60000 (2%)]\tLoss: 0.396159\n",
      "Train Epoch: 2 [1500/60000 (2%)]\tLoss: 0.010901\n",
      "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.547672\n",
      "Train Epoch: 2 [1700/60000 (3%)]\tLoss: 0.774562\n",
      "Train Epoch: 2 [1800/60000 (3%)]\tLoss: 0.080428\n",
      "Train Epoch: 2 [1900/60000 (3%)]\tLoss: 0.144218\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.066338\n",
      "Train Epoch: 2 [2100/60000 (4%)]\tLoss: 0.238261\n",
      "Train Epoch: 2 [2200/60000 (4%)]\tLoss: 0.090688\n",
      "Train Epoch: 2 [2300/60000 (4%)]\tLoss: 0.231718\n",
      "Train Epoch: 2 [2400/60000 (4%)]\tLoss: 0.516319\n",
      "Train Epoch: 2 [2500/60000 (4%)]\tLoss: 0.105217\n",
      "Train Epoch: 2 [2600/60000 (4%)]\tLoss: 0.117846\n",
      "Train Epoch: 2 [2700/60000 (4%)]\tLoss: 0.207339\n",
      "Train Epoch: 2 [2800/60000 (5%)]\tLoss: 0.606647\n",
      "Train Epoch: 2 [2900/60000 (5%)]\tLoss: 0.197815\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.152608\n",
      "Train Epoch: 2 [3100/60000 (5%)]\tLoss: 0.954682\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.071708\n",
      "Train Epoch: 2 [3300/60000 (6%)]\tLoss: 0.101370\n",
      "Train Epoch: 2 [3400/60000 (6%)]\tLoss: 0.030661\n",
      "Train Epoch: 2 [3500/60000 (6%)]\tLoss: 0.293123\n",
      "Train Epoch: 2 [3600/60000 (6%)]\tLoss: 0.263282\n",
      "Train Epoch: 2 [3700/60000 (6%)]\tLoss: 0.431727\n",
      "Train Epoch: 2 [3800/60000 (6%)]\tLoss: 0.213760\n",
      "Train Epoch: 2 [3900/60000 (6%)]\tLoss: 0.500834\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.089055\n",
      "Train Epoch: 2 [4100/60000 (7%)]\tLoss: 0.266387\n",
      "Train Epoch: 2 [4200/60000 (7%)]\tLoss: 0.369068\n",
      "Train Epoch: 2 [4300/60000 (7%)]\tLoss: 0.323175\n",
      "Train Epoch: 2 [4400/60000 (7%)]\tLoss: 0.233289\n",
      "Train Epoch: 2 [4500/60000 (8%)]\tLoss: 0.293959\n",
      "Train Epoch: 2 [4600/60000 (8%)]\tLoss: 0.089126\n",
      "Train Epoch: 2 [4700/60000 (8%)]\tLoss: 0.250080\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.125288\n",
      "Train Epoch: 2 [4900/60000 (8%)]\tLoss: 0.045928\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.238845\n",
      "Train Epoch: 2 [5100/60000 (8%)]\tLoss: 0.027872\n",
      "Train Epoch: 2 [5200/60000 (9%)]\tLoss: 1.036530\n",
      "Train Epoch: 2 [5300/60000 (9%)]\tLoss: 0.164390\n",
      "Train Epoch: 2 [5400/60000 (9%)]\tLoss: 0.017912\n",
      "Train Epoch: 2 [5500/60000 (9%)]\tLoss: 0.513823\n",
      "Train Epoch: 2 [5600/60000 (9%)]\tLoss: 0.350561\n",
      "Train Epoch: 2 [5700/60000 (10%)]\tLoss: 0.022692\n",
      "Train Epoch: 2 [5800/60000 (10%)]\tLoss: 0.017909\n",
      "Train Epoch: 2 [5900/60000 (10%)]\tLoss: 0.465465\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.010438\n",
      "Train Epoch: 2 [6100/60000 (10%)]\tLoss: 0.161120\n",
      "Train Epoch: 2 [6200/60000 (10%)]\tLoss: 0.112763\n",
      "Train Epoch: 2 [6300/60000 (10%)]\tLoss: 0.167665\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.302445\n",
      "Train Epoch: 2 [6500/60000 (11%)]\tLoss: 0.082104\n",
      "Train Epoch: 2 [6600/60000 (11%)]\tLoss: 1.040170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [6700/60000 (11%)]\tLoss: 0.142540\n",
      "Train Epoch: 2 [6800/60000 (11%)]\tLoss: 0.973073\n",
      "Train Epoch: 2 [6900/60000 (12%)]\tLoss: 0.212491\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.032405\n",
      "Train Epoch: 2 [7100/60000 (12%)]\tLoss: 0.161163\n",
      "Train Epoch: 2 [7200/60000 (12%)]\tLoss: 0.737788\n",
      "Train Epoch: 2 [7300/60000 (12%)]\tLoss: 1.208213\n",
      "Train Epoch: 2 [7400/60000 (12%)]\tLoss: 0.347416\n",
      "Train Epoch: 2 [7500/60000 (12%)]\tLoss: 0.529697\n",
      "Train Epoch: 2 [7600/60000 (13%)]\tLoss: 0.077541\n",
      "Train Epoch: 2 [7700/60000 (13%)]\tLoss: 0.210881\n",
      "Train Epoch: 2 [7800/60000 (13%)]\tLoss: 0.062136\n",
      "Train Epoch: 2 [7900/60000 (13%)]\tLoss: 0.087072\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.349041\n",
      "Train Epoch: 2 [8100/60000 (14%)]\tLoss: 0.057755\n",
      "Train Epoch: 2 [8200/60000 (14%)]\tLoss: 0.542485\n",
      "Train Epoch: 2 [8300/60000 (14%)]\tLoss: 0.053166\n",
      "Train Epoch: 2 [8400/60000 (14%)]\tLoss: 0.306152\n",
      "Train Epoch: 2 [8500/60000 (14%)]\tLoss: 1.505041\n",
      "Train Epoch: 2 [8600/60000 (14%)]\tLoss: 0.190956\n",
      "Train Epoch: 2 [8700/60000 (14%)]\tLoss: 0.632475\n",
      "Train Epoch: 2 [8800/60000 (15%)]\tLoss: 0.195293\n",
      "Train Epoch: 2 [8900/60000 (15%)]\tLoss: 0.270176\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.198737\n",
      "Train Epoch: 2 [9100/60000 (15%)]\tLoss: 0.102496\n",
      "Train Epoch: 2 [9200/60000 (15%)]\tLoss: 0.003632\n",
      "Train Epoch: 2 [9300/60000 (16%)]\tLoss: 0.066034\n",
      "Train Epoch: 2 [9400/60000 (16%)]\tLoss: 0.904295\n",
      "Train Epoch: 2 [9500/60000 (16%)]\tLoss: 0.265030\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.266929\n",
      "Train Epoch: 2 [9700/60000 (16%)]\tLoss: 0.119098\n",
      "Train Epoch: 2 [9800/60000 (16%)]\tLoss: 0.048651\n",
      "Train Epoch: 2 [9900/60000 (16%)]\tLoss: 0.082366\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.180909\n",
      "Train Epoch: 2 [10100/60000 (17%)]\tLoss: 0.173869\n",
      "Train Epoch: 2 [10200/60000 (17%)]\tLoss: 0.039622\n",
      "Train Epoch: 2 [10300/60000 (17%)]\tLoss: 0.237248\n",
      "Train Epoch: 2 [10400/60000 (17%)]\tLoss: 0.124813\n",
      "Train Epoch: 2 [10500/60000 (18%)]\tLoss: 0.183991\n",
      "Train Epoch: 2 [10600/60000 (18%)]\tLoss: 0.048207\n",
      "Train Epoch: 2 [10700/60000 (18%)]\tLoss: 0.358624\n",
      "Train Epoch: 2 [10800/60000 (18%)]\tLoss: 0.099333\n",
      "Train Epoch: 2 [10900/60000 (18%)]\tLoss: 0.015839\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.566625\n",
      "Train Epoch: 2 [11100/60000 (18%)]\tLoss: 0.159694\n",
      "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.780040\n",
      "Train Epoch: 2 [11300/60000 (19%)]\tLoss: 0.450026\n",
      "Train Epoch: 2 [11400/60000 (19%)]\tLoss: 1.158855\n",
      "Train Epoch: 2 [11500/60000 (19%)]\tLoss: 0.564298\n",
      "Train Epoch: 2 [11600/60000 (19%)]\tLoss: 0.428687\n",
      "Train Epoch: 2 [11700/60000 (20%)]\tLoss: 0.158291\n",
      "Train Epoch: 2 [11800/60000 (20%)]\tLoss: 0.012264\n",
      "Train Epoch: 2 [11900/60000 (20%)]\tLoss: 0.040507\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.232998\n",
      "Train Epoch: 2 [12100/60000 (20%)]\tLoss: 0.201986\n",
      "Train Epoch: 2 [12200/60000 (20%)]\tLoss: 0.060108\n",
      "Train Epoch: 2 [12300/60000 (20%)]\tLoss: 0.187465\n",
      "Train Epoch: 2 [12400/60000 (21%)]\tLoss: 0.089773\n",
      "Train Epoch: 2 [12500/60000 (21%)]\tLoss: 0.235522\n",
      "Train Epoch: 2 [12600/60000 (21%)]\tLoss: 1.091609\n",
      "Train Epoch: 2 [12700/60000 (21%)]\tLoss: 0.061375\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.085309\n",
      "Train Epoch: 2 [12900/60000 (22%)]\tLoss: 0.077307\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.332543\n",
      "Train Epoch: 2 [13100/60000 (22%)]\tLoss: 0.383993\n",
      "Train Epoch: 2 [13200/60000 (22%)]\tLoss: 0.018970\n",
      "Train Epoch: 2 [13300/60000 (22%)]\tLoss: 0.037450\n",
      "Train Epoch: 2 [13400/60000 (22%)]\tLoss: 0.003401\n",
      "Train Epoch: 2 [13500/60000 (22%)]\tLoss: 0.136029\n",
      "Train Epoch: 2 [13600/60000 (23%)]\tLoss: 0.156910\n",
      "Train Epoch: 2 [13700/60000 (23%)]\tLoss: 0.060490\n",
      "Train Epoch: 2 [13800/60000 (23%)]\tLoss: 0.159450\n",
      "Train Epoch: 2 [13900/60000 (23%)]\tLoss: 0.196321\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.132799\n",
      "Train Epoch: 2 [14100/60000 (24%)]\tLoss: 0.006624\n",
      "Train Epoch: 2 [14200/60000 (24%)]\tLoss: 0.345051\n",
      "Train Epoch: 2 [14300/60000 (24%)]\tLoss: 0.010657\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.494035\n",
      "Train Epoch: 2 [14500/60000 (24%)]\tLoss: 0.440764\n",
      "Train Epoch: 2 [14600/60000 (24%)]\tLoss: 0.152920\n",
      "Train Epoch: 2 [14700/60000 (24%)]\tLoss: 0.301574\n",
      "Train Epoch: 2 [14800/60000 (25%)]\tLoss: 0.078841\n",
      "Train Epoch: 2 [14900/60000 (25%)]\tLoss: 0.025569\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.251077\n",
      "Train Epoch: 2 [15100/60000 (25%)]\tLoss: 0.724206\n",
      "Train Epoch: 2 [15200/60000 (25%)]\tLoss: 0.143169\n",
      "Train Epoch: 2 [15300/60000 (26%)]\tLoss: 0.179507\n",
      "Train Epoch: 2 [15400/60000 (26%)]\tLoss: 0.038515\n",
      "Train Epoch: 2 [15500/60000 (26%)]\tLoss: 0.333682\n",
      "Train Epoch: 2 [15600/60000 (26%)]\tLoss: 0.056644\n",
      "Train Epoch: 2 [15700/60000 (26%)]\tLoss: 0.129424\n",
      "Train Epoch: 2 [15800/60000 (26%)]\tLoss: 0.309886\n",
      "Train Epoch: 2 [15900/60000 (26%)]\tLoss: 0.074784\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.345381\n",
      "Train Epoch: 2 [16100/60000 (27%)]\tLoss: 0.133491\n",
      "Train Epoch: 2 [16200/60000 (27%)]\tLoss: 0.023456\n",
      "Train Epoch: 2 [16300/60000 (27%)]\tLoss: 0.344471\n",
      "Train Epoch: 2 [16400/60000 (27%)]\tLoss: 0.041792\n",
      "Train Epoch: 2 [16500/60000 (28%)]\tLoss: 0.151987\n",
      "Train Epoch: 2 [16600/60000 (28%)]\tLoss: 0.329053\n",
      "Train Epoch: 2 [16700/60000 (28%)]\tLoss: 0.172769\n",
      "Train Epoch: 2 [16800/60000 (28%)]\tLoss: 0.147536\n",
      "Train Epoch: 2 [16900/60000 (28%)]\tLoss: 0.124110\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.135403\n",
      "Train Epoch: 2 [17100/60000 (28%)]\tLoss: 0.695434\n",
      "Train Epoch: 2 [17200/60000 (29%)]\tLoss: 0.316571\n",
      "Train Epoch: 2 [17300/60000 (29%)]\tLoss: 0.188449\n",
      "Train Epoch: 2 [17400/60000 (29%)]\tLoss: 1.037290\n",
      "Train Epoch: 2 [17500/60000 (29%)]\tLoss: 0.062387\n",
      "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.038432\n",
      "Train Epoch: 2 [17700/60000 (30%)]\tLoss: 0.277124\n",
      "Train Epoch: 2 [17800/60000 (30%)]\tLoss: 0.216010\n",
      "Train Epoch: 2 [17900/60000 (30%)]\tLoss: 0.243682\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.784531\n",
      "Train Epoch: 2 [18100/60000 (30%)]\tLoss: 0.020967\n",
      "Train Epoch: 2 [18200/60000 (30%)]\tLoss: 0.099454\n",
      "Train Epoch: 2 [18300/60000 (30%)]\tLoss: 0.153743\n",
      "Train Epoch: 2 [18400/60000 (31%)]\tLoss: 0.010346\n",
      "Train Epoch: 2 [18500/60000 (31%)]\tLoss: 0.243684\n",
      "Train Epoch: 2 [18600/60000 (31%)]\tLoss: 0.068382\n",
      "Train Epoch: 2 [18700/60000 (31%)]\tLoss: 0.144190\n",
      "Train Epoch: 2 [18800/60000 (31%)]\tLoss: 0.008479\n",
      "Train Epoch: 2 [18900/60000 (32%)]\tLoss: 0.821222\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.386129\n",
      "Train Epoch: 2 [19100/60000 (32%)]\tLoss: 0.446430\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.048516\n",
      "Train Epoch: 2 [19300/60000 (32%)]\tLoss: 0.539660\n",
      "Train Epoch: 2 [19400/60000 (32%)]\tLoss: 0.746702\n",
      "Train Epoch: 2 [19500/60000 (32%)]\tLoss: 0.010011\n",
      "Train Epoch: 2 [19600/60000 (33%)]\tLoss: 0.027864\n",
      "Train Epoch: 2 [19700/60000 (33%)]\tLoss: 0.046516\n",
      "Train Epoch: 2 [19800/60000 (33%)]\tLoss: 0.520517\n",
      "Train Epoch: 2 [19900/60000 (33%)]\tLoss: 0.011184\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.083557\n",
      "Train Epoch: 2 [20100/60000 (34%)]\tLoss: 0.149216\n",
      "Train Epoch: 2 [20200/60000 (34%)]\tLoss: 0.098864\n",
      "Train Epoch: 2 [20300/60000 (34%)]\tLoss: 0.108417\n",
      "Train Epoch: 2 [20400/60000 (34%)]\tLoss: 0.192633\n",
      "Train Epoch: 2 [20500/60000 (34%)]\tLoss: 0.000731\n",
      "Train Epoch: 2 [20600/60000 (34%)]\tLoss: 0.753789\n",
      "Train Epoch: 2 [20700/60000 (34%)]\tLoss: 0.097415\n",
      "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.335095\n",
      "Train Epoch: 2 [20900/60000 (35%)]\tLoss: 0.832030\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.031152\n",
      "Train Epoch: 2 [21100/60000 (35%)]\tLoss: 0.201000\n",
      "Train Epoch: 2 [21200/60000 (35%)]\tLoss: 0.016728\n",
      "Train Epoch: 2 [21300/60000 (36%)]\tLoss: 0.007728\n",
      "Train Epoch: 2 [21400/60000 (36%)]\tLoss: 0.225472\n",
      "Train Epoch: 2 [21500/60000 (36%)]\tLoss: 0.219819\n",
      "Train Epoch: 2 [21600/60000 (36%)]\tLoss: 0.449144\n",
      "Train Epoch: 2 [21700/60000 (36%)]\tLoss: 0.758789\n",
      "Train Epoch: 2 [21800/60000 (36%)]\tLoss: 0.360914\n",
      "Train Epoch: 2 [21900/60000 (36%)]\tLoss: 0.098388\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.012151\n",
      "Train Epoch: 2 [22100/60000 (37%)]\tLoss: 0.160490\n",
      "Train Epoch: 2 [22200/60000 (37%)]\tLoss: 0.660835\n",
      "Train Epoch: 2 [22300/60000 (37%)]\tLoss: 1.497307\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.367328\n",
      "Train Epoch: 2 [22500/60000 (38%)]\tLoss: 0.013550\n",
      "Train Epoch: 2 [22600/60000 (38%)]\tLoss: 0.191914\n",
      "Train Epoch: 2 [22700/60000 (38%)]\tLoss: 0.476667\n",
      "Train Epoch: 2 [22800/60000 (38%)]\tLoss: 0.497017\n",
      "Train Epoch: 2 [22900/60000 (38%)]\tLoss: 0.952564\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.073090\n",
      "Train Epoch: 2 [23100/60000 (38%)]\tLoss: 0.184039\n",
      "Train Epoch: 2 [23200/60000 (39%)]\tLoss: 0.312626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [23300/60000 (39%)]\tLoss: 0.368268\n",
      "Train Epoch: 2 [23400/60000 (39%)]\tLoss: 0.408180\n",
      "Train Epoch: 2 [23500/60000 (39%)]\tLoss: 0.572915\n",
      "Train Epoch: 2 [23600/60000 (39%)]\tLoss: 0.615393\n",
      "Train Epoch: 2 [23700/60000 (40%)]\tLoss: 0.166507\n",
      "Train Epoch: 2 [23800/60000 (40%)]\tLoss: 0.393112\n",
      "Train Epoch: 2 [23900/60000 (40%)]\tLoss: 0.317010\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.296443\n",
      "Train Epoch: 2 [24100/60000 (40%)]\tLoss: 0.011902\n",
      "Train Epoch: 2 [24200/60000 (40%)]\tLoss: 0.356401\n",
      "Train Epoch: 2 [24300/60000 (40%)]\tLoss: 0.009043\n",
      "Train Epoch: 2 [24400/60000 (41%)]\tLoss: 0.561205\n",
      "Train Epoch: 2 [24500/60000 (41%)]\tLoss: 0.228591\n",
      "Train Epoch: 2 [24600/60000 (41%)]\tLoss: 0.961771\n",
      "Train Epoch: 2 [24700/60000 (41%)]\tLoss: 0.145264\n",
      "Train Epoch: 2 [24800/60000 (41%)]\tLoss: 0.214323\n",
      "Train Epoch: 2 [24900/60000 (42%)]\tLoss: 0.001157\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.030980\n",
      "Train Epoch: 2 [25100/60000 (42%)]\tLoss: 0.269607\n",
      "Train Epoch: 2 [25200/60000 (42%)]\tLoss: 0.007342\n",
      "Train Epoch: 2 [25300/60000 (42%)]\tLoss: 0.710081\n",
      "Train Epoch: 2 [25400/60000 (42%)]\tLoss: 0.334760\n",
      "Train Epoch: 2 [25500/60000 (42%)]\tLoss: 0.591256\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.545062\n",
      "Train Epoch: 2 [25700/60000 (43%)]\tLoss: 0.226039\n",
      "Train Epoch: 2 [25800/60000 (43%)]\tLoss: 1.088221\n",
      "Train Epoch: 2 [25900/60000 (43%)]\tLoss: 0.287421\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.622949\n",
      "Train Epoch: 2 [26100/60000 (44%)]\tLoss: 0.103482\n",
      "Train Epoch: 2 [26200/60000 (44%)]\tLoss: 0.039560\n",
      "Train Epoch: 2 [26300/60000 (44%)]\tLoss: 0.025201\n",
      "Train Epoch: 2 [26400/60000 (44%)]\tLoss: 0.236280\n",
      "Train Epoch: 2 [26500/60000 (44%)]\tLoss: 0.069008\n",
      "Train Epoch: 2 [26600/60000 (44%)]\tLoss: 0.065420\n",
      "Train Epoch: 2 [26700/60000 (44%)]\tLoss: 0.420847\n",
      "Train Epoch: 2 [26800/60000 (45%)]\tLoss: 0.246140\n",
      "Train Epoch: 2 [26900/60000 (45%)]\tLoss: 0.112611\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.536888\n",
      "Train Epoch: 2 [27100/60000 (45%)]\tLoss: 0.039856\n",
      "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.776517\n",
      "Train Epoch: 2 [27300/60000 (46%)]\tLoss: 0.333433\n",
      "Train Epoch: 2 [27400/60000 (46%)]\tLoss: 0.050935\n",
      "Train Epoch: 2 [27500/60000 (46%)]\tLoss: 0.264589\n",
      "Train Epoch: 2 [27600/60000 (46%)]\tLoss: 0.063940\n",
      "Train Epoch: 2 [27700/60000 (46%)]\tLoss: 0.036206\n",
      "Train Epoch: 2 [27800/60000 (46%)]\tLoss: 0.070954\n",
      "Train Epoch: 2 [27900/60000 (46%)]\tLoss: 0.148985\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.340394\n",
      "Train Epoch: 2 [28100/60000 (47%)]\tLoss: 0.006285\n",
      "Train Epoch: 2 [28200/60000 (47%)]\tLoss: 0.124767\n",
      "Train Epoch: 2 [28300/60000 (47%)]\tLoss: 0.053697\n",
      "Train Epoch: 2 [28400/60000 (47%)]\tLoss: 1.277830\n",
      "Train Epoch: 2 [28500/60000 (48%)]\tLoss: 0.892289\n",
      "Train Epoch: 2 [28600/60000 (48%)]\tLoss: 0.064157\n",
      "Train Epoch: 2 [28700/60000 (48%)]\tLoss: 0.060615\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.019431\n",
      "Train Epoch: 2 [28900/60000 (48%)]\tLoss: 0.153552\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.584217\n",
      "Train Epoch: 2 [29100/60000 (48%)]\tLoss: 0.490667\n",
      "Train Epoch: 2 [29200/60000 (49%)]\tLoss: 0.299169\n",
      "Train Epoch: 2 [29300/60000 (49%)]\tLoss: 1.001569\n",
      "Train Epoch: 2 [29400/60000 (49%)]\tLoss: 0.079610\n",
      "Train Epoch: 2 [29500/60000 (49%)]\tLoss: 0.162962\n",
      "Train Epoch: 2 [29600/60000 (49%)]\tLoss: 0.634166\n",
      "Train Epoch: 2 [29700/60000 (50%)]\tLoss: 0.067362\n",
      "Train Epoch: 2 [29800/60000 (50%)]\tLoss: 0.418052\n",
      "Train Epoch: 2 [29900/60000 (50%)]\tLoss: 0.895122\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.034373\n",
      "Train Epoch: 2 [30100/60000 (50%)]\tLoss: 0.043693\n",
      "Train Epoch: 2 [30200/60000 (50%)]\tLoss: 0.145592\n",
      "Train Epoch: 2 [30300/60000 (50%)]\tLoss: 0.052385\n",
      "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.166072\n",
      "Train Epoch: 2 [30500/60000 (51%)]\tLoss: 0.226663\n",
      "Train Epoch: 2 [30600/60000 (51%)]\tLoss: 1.477405\n",
      "Train Epoch: 2 [30700/60000 (51%)]\tLoss: 0.093119\n",
      "Train Epoch: 2 [30800/60000 (51%)]\tLoss: 0.238780\n",
      "Train Epoch: 2 [30900/60000 (52%)]\tLoss: 0.153436\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.270887\n",
      "Train Epoch: 2 [31100/60000 (52%)]\tLoss: 0.401336\n",
      "Train Epoch: 2 [31200/60000 (52%)]\tLoss: 0.173593\n",
      "Train Epoch: 2 [31300/60000 (52%)]\tLoss: 0.911819\n",
      "Train Epoch: 2 [31400/60000 (52%)]\tLoss: 0.036610\n",
      "Train Epoch: 2 [31500/60000 (52%)]\tLoss: 0.102047\n",
      "Train Epoch: 2 [31600/60000 (53%)]\tLoss: 0.177176\n",
      "Train Epoch: 2 [31700/60000 (53%)]\tLoss: 0.589351\n",
      "Train Epoch: 2 [31800/60000 (53%)]\tLoss: 0.067264\n",
      "Train Epoch: 2 [31900/60000 (53%)]\tLoss: 0.334540\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.036105\n",
      "Train Epoch: 2 [32100/60000 (54%)]\tLoss: 0.225628\n",
      "Train Epoch: 2 [32200/60000 (54%)]\tLoss: 0.156783\n",
      "Train Epoch: 2 [32300/60000 (54%)]\tLoss: 0.202493\n",
      "Train Epoch: 2 [32400/60000 (54%)]\tLoss: 0.017872\n",
      "Train Epoch: 2 [32500/60000 (54%)]\tLoss: 0.225237\n",
      "Train Epoch: 2 [32600/60000 (54%)]\tLoss: 0.005766\n",
      "Train Epoch: 2 [32700/60000 (54%)]\tLoss: 0.779920\n",
      "Train Epoch: 2 [32800/60000 (55%)]\tLoss: 0.270429\n",
      "Train Epoch: 2 [32900/60000 (55%)]\tLoss: 0.153207\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.083269\n",
      "Train Epoch: 2 [33100/60000 (55%)]\tLoss: 0.021806\n",
      "Train Epoch: 2 [33200/60000 (55%)]\tLoss: 0.056392\n",
      "Train Epoch: 2 [33300/60000 (56%)]\tLoss: 0.156823\n",
      "Train Epoch: 2 [33400/60000 (56%)]\tLoss: 0.138511\n",
      "Train Epoch: 2 [33500/60000 (56%)]\tLoss: 0.165533\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.173668\n",
      "Train Epoch: 2 [33700/60000 (56%)]\tLoss: 0.038317\n",
      "Train Epoch: 2 [33800/60000 (56%)]\tLoss: 0.385550\n",
      "Train Epoch: 2 [33900/60000 (56%)]\tLoss: 0.050502\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.057828\n",
      "Train Epoch: 2 [34100/60000 (57%)]\tLoss: 0.072907\n",
      "Train Epoch: 2 [34200/60000 (57%)]\tLoss: 0.112694\n",
      "Train Epoch: 2 [34300/60000 (57%)]\tLoss: 0.955122\n",
      "Train Epoch: 2 [34400/60000 (57%)]\tLoss: 0.102734\n",
      "Train Epoch: 2 [34500/60000 (58%)]\tLoss: 0.138845\n",
      "Train Epoch: 2 [34600/60000 (58%)]\tLoss: 0.240517\n",
      "Train Epoch: 2 [34700/60000 (58%)]\tLoss: 0.184171\n",
      "Train Epoch: 2 [34800/60000 (58%)]\tLoss: 0.168055\n",
      "Train Epoch: 2 [34900/60000 (58%)]\tLoss: 0.077849\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.659985\n",
      "Train Epoch: 2 [35100/60000 (58%)]\tLoss: 0.667447\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.047756\n",
      "Train Epoch: 2 [35300/60000 (59%)]\tLoss: 0.201407\n",
      "Train Epoch: 2 [35400/60000 (59%)]\tLoss: 0.161214\n",
      "Train Epoch: 2 [35500/60000 (59%)]\tLoss: 0.037316\n",
      "Train Epoch: 2 [35600/60000 (59%)]\tLoss: 0.308437\n",
      "Train Epoch: 2 [35700/60000 (60%)]\tLoss: 0.106733\n",
      "Train Epoch: 2 [35800/60000 (60%)]\tLoss: 0.265189\n",
      "Train Epoch: 2 [35900/60000 (60%)]\tLoss: 0.230211\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.069273\n",
      "Train Epoch: 2 [36100/60000 (60%)]\tLoss: 0.122762\n",
      "Train Epoch: 2 [36200/60000 (60%)]\tLoss: 0.402143\n",
      "Train Epoch: 2 [36300/60000 (60%)]\tLoss: 0.066751\n",
      "Train Epoch: 2 [36400/60000 (61%)]\tLoss: 0.090959\n",
      "Train Epoch: 2 [36500/60000 (61%)]\tLoss: 0.161194\n",
      "Train Epoch: 2 [36600/60000 (61%)]\tLoss: 0.039358\n",
      "Train Epoch: 2 [36700/60000 (61%)]\tLoss: 0.080122\n",
      "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.009192\n",
      "Train Epoch: 2 [36900/60000 (62%)]\tLoss: 0.207125\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.429482\n",
      "Train Epoch: 2 [37100/60000 (62%)]\tLoss: 0.117309\n",
      "Train Epoch: 2 [37200/60000 (62%)]\tLoss: 0.104956\n",
      "Train Epoch: 2 [37300/60000 (62%)]\tLoss: 0.514092\n",
      "Train Epoch: 2 [37400/60000 (62%)]\tLoss: 0.140817\n",
      "Train Epoch: 2 [37500/60000 (62%)]\tLoss: 0.368831\n",
      "Train Epoch: 2 [37600/60000 (63%)]\tLoss: 0.007403\n",
      "Train Epoch: 2 [37700/60000 (63%)]\tLoss: 0.188924\n",
      "Train Epoch: 2 [37800/60000 (63%)]\tLoss: 0.186442\n",
      "Train Epoch: 2 [37900/60000 (63%)]\tLoss: 0.167609\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.051792\n",
      "Train Epoch: 2 [38100/60000 (64%)]\tLoss: 0.371650\n",
      "Train Epoch: 2 [38200/60000 (64%)]\tLoss: 0.137637\n",
      "Train Epoch: 2 [38300/60000 (64%)]\tLoss: 0.278121\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.164915\n",
      "Train Epoch: 2 [38500/60000 (64%)]\tLoss: 1.461326\n",
      "Train Epoch: 2 [38600/60000 (64%)]\tLoss: 0.156367\n",
      "Train Epoch: 2 [38700/60000 (64%)]\tLoss: 0.035106\n",
      "Train Epoch: 2 [38800/60000 (65%)]\tLoss: 0.258478\n",
      "Train Epoch: 2 [38900/60000 (65%)]\tLoss: 0.277282\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.523607\n",
      "Train Epoch: 2 [39100/60000 (65%)]\tLoss: 0.285379\n",
      "Train Epoch: 2 [39200/60000 (65%)]\tLoss: 0.026447\n",
      "Train Epoch: 2 [39300/60000 (66%)]\tLoss: 0.629033\n",
      "Train Epoch: 2 [39400/60000 (66%)]\tLoss: 0.089828\n",
      "Train Epoch: 2 [39500/60000 (66%)]\tLoss: 0.151385\n",
      "Train Epoch: 2 [39600/60000 (66%)]\tLoss: 0.425070\n",
      "Train Epoch: 2 [39700/60000 (66%)]\tLoss: 0.568035\n",
      "Train Epoch: 2 [39800/60000 (66%)]\tLoss: 0.030212\n",
      "Train Epoch: 2 [39900/60000 (66%)]\tLoss: 0.042486\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.461630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [40100/60000 (67%)]\tLoss: 0.127371\n",
      "Train Epoch: 2 [40200/60000 (67%)]\tLoss: 0.061909\n",
      "Train Epoch: 2 [40300/60000 (67%)]\tLoss: 0.098568\n",
      "Train Epoch: 2 [40400/60000 (67%)]\tLoss: 0.119703\n",
      "Train Epoch: 2 [40500/60000 (68%)]\tLoss: 0.021741\n",
      "Train Epoch: 2 [40600/60000 (68%)]\tLoss: 0.000783\n",
      "Train Epoch: 2 [40700/60000 (68%)]\tLoss: 0.093330\n",
      "Train Epoch: 2 [40800/60000 (68%)]\tLoss: 0.091815\n",
      "Train Epoch: 2 [40900/60000 (68%)]\tLoss: 0.037559\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.194885\n",
      "Train Epoch: 2 [41100/60000 (68%)]\tLoss: 0.087579\n",
      "Train Epoch: 2 [41200/60000 (69%)]\tLoss: 0.835088\n",
      "Train Epoch: 2 [41300/60000 (69%)]\tLoss: 0.326705\n",
      "Train Epoch: 2 [41400/60000 (69%)]\tLoss: 0.331400\n",
      "Train Epoch: 2 [41500/60000 (69%)]\tLoss: 0.369273\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.965340\n",
      "Train Epoch: 2 [41700/60000 (70%)]\tLoss: 0.055291\n",
      "Train Epoch: 2 [41800/60000 (70%)]\tLoss: 0.028612\n",
      "Train Epoch: 2 [41900/60000 (70%)]\tLoss: 1.053399\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.015656\n",
      "Train Epoch: 2 [42100/60000 (70%)]\tLoss: 0.267052\n",
      "Train Epoch: 2 [42200/60000 (70%)]\tLoss: 0.248658\n",
      "Train Epoch: 2 [42300/60000 (70%)]\tLoss: 0.015828\n",
      "Train Epoch: 2 [42400/60000 (71%)]\tLoss: 0.071904\n",
      "Train Epoch: 2 [42500/60000 (71%)]\tLoss: 0.501939\n",
      "Train Epoch: 2 [42600/60000 (71%)]\tLoss: 0.121219\n",
      "Train Epoch: 2 [42700/60000 (71%)]\tLoss: 0.311276\n",
      "Train Epoch: 2 [42800/60000 (71%)]\tLoss: 0.161708\n",
      "Train Epoch: 2 [42900/60000 (72%)]\tLoss: 0.332585\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.012416\n",
      "Train Epoch: 2 [43100/60000 (72%)]\tLoss: 0.077842\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.491367\n",
      "Train Epoch: 2 [43300/60000 (72%)]\tLoss: 0.128726\n",
      "Train Epoch: 2 [43400/60000 (72%)]\tLoss: 0.226377\n",
      "Train Epoch: 2 [43500/60000 (72%)]\tLoss: 0.072983\n",
      "Train Epoch: 2 [43600/60000 (73%)]\tLoss: 0.592588\n",
      "Train Epoch: 2 [43700/60000 (73%)]\tLoss: 0.039705\n",
      "Train Epoch: 2 [43800/60000 (73%)]\tLoss: 0.012042\n",
      "Train Epoch: 2 [43900/60000 (73%)]\tLoss: 0.444382\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.006864\n",
      "Train Epoch: 2 [44100/60000 (74%)]\tLoss: 0.175335\n",
      "Train Epoch: 2 [44200/60000 (74%)]\tLoss: 0.059313\n",
      "Train Epoch: 2 [44300/60000 (74%)]\tLoss: 0.072330\n",
      "Train Epoch: 2 [44400/60000 (74%)]\tLoss: 0.051536\n",
      "Train Epoch: 2 [44500/60000 (74%)]\tLoss: 0.191784\n",
      "Train Epoch: 2 [44600/60000 (74%)]\tLoss: 0.155060\n",
      "Train Epoch: 2 [44700/60000 (74%)]\tLoss: 0.110887\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.432519\n",
      "Train Epoch: 2 [44900/60000 (75%)]\tLoss: 0.133940\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.435318\n",
      "Train Epoch: 2 [45100/60000 (75%)]\tLoss: 0.021016\n",
      "Train Epoch: 2 [45200/60000 (75%)]\tLoss: 0.159993\n",
      "Train Epoch: 2 [45300/60000 (76%)]\tLoss: 0.278930\n",
      "Train Epoch: 2 [45400/60000 (76%)]\tLoss: 0.466418\n",
      "Train Epoch: 2 [45500/60000 (76%)]\tLoss: 0.057480\n",
      "Train Epoch: 2 [45600/60000 (76%)]\tLoss: 0.932106\n",
      "Train Epoch: 2 [45700/60000 (76%)]\tLoss: 0.469519\n",
      "Train Epoch: 2 [45800/60000 (76%)]\tLoss: 0.038186\n",
      "Train Epoch: 2 [45900/60000 (76%)]\tLoss: 0.029906\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.485758\n",
      "Train Epoch: 2 [46100/60000 (77%)]\tLoss: 0.188522\n",
      "Train Epoch: 2 [46200/60000 (77%)]\tLoss: 0.359984\n",
      "Train Epoch: 2 [46300/60000 (77%)]\tLoss: 0.024842\n",
      "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.286437\n",
      "Train Epoch: 2 [46500/60000 (78%)]\tLoss: 0.181413\n",
      "Train Epoch: 2 [46600/60000 (78%)]\tLoss: 0.147737\n",
      "Train Epoch: 2 [46700/60000 (78%)]\tLoss: 0.203725\n",
      "Train Epoch: 2 [46800/60000 (78%)]\tLoss: 0.048721\n",
      "Train Epoch: 2 [46900/60000 (78%)]\tLoss: 0.206100\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.030319\n",
      "Train Epoch: 2 [47100/60000 (78%)]\tLoss: 0.008111\n",
      "Train Epoch: 2 [47200/60000 (79%)]\tLoss: 0.541141\n",
      "Train Epoch: 2 [47300/60000 (79%)]\tLoss: 0.588563\n",
      "Train Epoch: 2 [47400/60000 (79%)]\tLoss: 0.316731\n",
      "Train Epoch: 2 [47500/60000 (79%)]\tLoss: 0.034494\n",
      "Train Epoch: 2 [47600/60000 (79%)]\tLoss: 0.029962\n",
      "Train Epoch: 2 [47700/60000 (80%)]\tLoss: 0.415139\n",
      "Train Epoch: 2 [47800/60000 (80%)]\tLoss: 0.025019\n",
      "Train Epoch: 2 [47900/60000 (80%)]\tLoss: 0.805563\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.170539\n",
      "Train Epoch: 2 [48100/60000 (80%)]\tLoss: 0.234604\n",
      "Train Epoch: 2 [48200/60000 (80%)]\tLoss: 0.367148\n",
      "Train Epoch: 2 [48300/60000 (80%)]\tLoss: 0.299635\n",
      "Train Epoch: 2 [48400/60000 (81%)]\tLoss: 0.137242\n",
      "Train Epoch: 2 [48500/60000 (81%)]\tLoss: 0.054886\n",
      "Train Epoch: 2 [48600/60000 (81%)]\tLoss: 0.059507\n",
      "Train Epoch: 2 [48700/60000 (81%)]\tLoss: 0.552379\n",
      "Train Epoch: 2 [48800/60000 (81%)]\tLoss: 1.058107\n",
      "Train Epoch: 2 [48900/60000 (82%)]\tLoss: 0.120251\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.010828\n",
      "Train Epoch: 2 [49100/60000 (82%)]\tLoss: 0.109069\n",
      "Train Epoch: 2 [49200/60000 (82%)]\tLoss: 0.411676\n",
      "Train Epoch: 2 [49300/60000 (82%)]\tLoss: 0.018214\n",
      "Train Epoch: 2 [49400/60000 (82%)]\tLoss: 0.005814\n",
      "Train Epoch: 2 [49500/60000 (82%)]\tLoss: 0.258445\n",
      "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.559854\n",
      "Train Epoch: 2 [49700/60000 (83%)]\tLoss: 0.310336\n",
      "Train Epoch: 2 [49800/60000 (83%)]\tLoss: 0.031171\n",
      "Train Epoch: 2 [49900/60000 (83%)]\tLoss: 0.411981\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.055140\n",
      "Train Epoch: 2 [50100/60000 (84%)]\tLoss: 0.155125\n",
      "Train Epoch: 2 [50200/60000 (84%)]\tLoss: 0.715661\n",
      "Train Epoch: 2 [50300/60000 (84%)]\tLoss: 0.050147\n",
      "Train Epoch: 2 [50400/60000 (84%)]\tLoss: 0.254853\n",
      "Train Epoch: 2 [50500/60000 (84%)]\tLoss: 0.308656\n",
      "Train Epoch: 2 [50600/60000 (84%)]\tLoss: 0.204651\n",
      "Train Epoch: 2 [50700/60000 (84%)]\tLoss: 0.119894\n",
      "Train Epoch: 2 [50800/60000 (85%)]\tLoss: 0.474190\n",
      "Train Epoch: 2 [50900/60000 (85%)]\tLoss: 0.202134\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.069326\n",
      "Train Epoch: 2 [51100/60000 (85%)]\tLoss: 0.330302\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.623681\n",
      "Train Epoch: 2 [51300/60000 (86%)]\tLoss: 0.057512\n",
      "Train Epoch: 2 [51400/60000 (86%)]\tLoss: 0.514783\n",
      "Train Epoch: 2 [51500/60000 (86%)]\tLoss: 0.116566\n",
      "Train Epoch: 2 [51600/60000 (86%)]\tLoss: 0.400881\n",
      "Train Epoch: 2 [51700/60000 (86%)]\tLoss: 0.217260\n",
      "Train Epoch: 2 [51800/60000 (86%)]\tLoss: 0.002525\n",
      "Train Epoch: 2 [51900/60000 (86%)]\tLoss: 0.024974\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.059788\n",
      "Train Epoch: 2 [52100/60000 (87%)]\tLoss: 0.132608\n",
      "Train Epoch: 2 [52200/60000 (87%)]\tLoss: 0.059604\n",
      "Train Epoch: 2 [52300/60000 (87%)]\tLoss: 0.270281\n",
      "Train Epoch: 2 [52400/60000 (87%)]\tLoss: 0.366715\n",
      "Train Epoch: 2 [52500/60000 (88%)]\tLoss: 0.663076\n",
      "Train Epoch: 2 [52600/60000 (88%)]\tLoss: 0.226940\n",
      "Train Epoch: 2 [52700/60000 (88%)]\tLoss: 1.161754\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.488042\n",
      "Train Epoch: 2 [52900/60000 (88%)]\tLoss: 0.209352\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.505265\n",
      "Train Epoch: 2 [53100/60000 (88%)]\tLoss: 0.146418\n",
      "Train Epoch: 2 [53200/60000 (89%)]\tLoss: 0.180200\n",
      "Train Epoch: 2 [53300/60000 (89%)]\tLoss: 0.179176\n",
      "Train Epoch: 2 [53400/60000 (89%)]\tLoss: 0.133063\n",
      "Train Epoch: 2 [53500/60000 (89%)]\tLoss: 0.326210\n",
      "Train Epoch: 2 [53600/60000 (89%)]\tLoss: 0.372928\n",
      "Train Epoch: 2 [53700/60000 (90%)]\tLoss: 0.531868\n",
      "Train Epoch: 2 [53800/60000 (90%)]\tLoss: 0.318793\n",
      "Train Epoch: 2 [53900/60000 (90%)]\tLoss: 0.153111\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.062738\n",
      "Train Epoch: 2 [54100/60000 (90%)]\tLoss: 0.074719\n",
      "Train Epoch: 2 [54200/60000 (90%)]\tLoss: 0.020751\n",
      "Train Epoch: 2 [54300/60000 (90%)]\tLoss: 0.052973\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.078786\n",
      "Train Epoch: 2 [54500/60000 (91%)]\tLoss: 0.209037\n",
      "Train Epoch: 2 [54600/60000 (91%)]\tLoss: 0.841879\n",
      "Train Epoch: 2 [54700/60000 (91%)]\tLoss: 0.275888\n",
      "Train Epoch: 2 [54800/60000 (91%)]\tLoss: 0.280009\n",
      "Train Epoch: 2 [54900/60000 (92%)]\tLoss: 0.088743\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.081046\n",
      "Train Epoch: 2 [55100/60000 (92%)]\tLoss: 0.029911\n",
      "Train Epoch: 2 [55200/60000 (92%)]\tLoss: 0.282592\n",
      "Train Epoch: 2 [55300/60000 (92%)]\tLoss: 0.102866\n",
      "Train Epoch: 2 [55400/60000 (92%)]\tLoss: 0.001820\n",
      "Train Epoch: 2 [55500/60000 (92%)]\tLoss: 0.010220\n",
      "Train Epoch: 2 [55600/60000 (93%)]\tLoss: 0.175062\n",
      "Train Epoch: 2 [55700/60000 (93%)]\tLoss: 0.249220\n",
      "Train Epoch: 2 [55800/60000 (93%)]\tLoss: 0.043072\n",
      "Train Epoch: 2 [55900/60000 (93%)]\tLoss: 0.055259\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.032460\n",
      "Train Epoch: 2 [56100/60000 (94%)]\tLoss: 0.195954\n",
      "Train Epoch: 2 [56200/60000 (94%)]\tLoss: 0.107444\n",
      "Train Epoch: 2 [56300/60000 (94%)]\tLoss: 0.116606\n",
      "Train Epoch: 2 [56400/60000 (94%)]\tLoss: 0.071352\n",
      "Train Epoch: 2 [56500/60000 (94%)]\tLoss: 0.363505\n",
      "Train Epoch: 2 [56600/60000 (94%)]\tLoss: 0.228698\n",
      "Train Epoch: 2 [56700/60000 (94%)]\tLoss: 0.052070\n",
      "Train Epoch: 2 [56800/60000 (95%)]\tLoss: 0.464804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [56900/60000 (95%)]\tLoss: 0.327909\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.926464\n",
      "Train Epoch: 2 [57100/60000 (95%)]\tLoss: 0.181776\n",
      "Train Epoch: 2 [57200/60000 (95%)]\tLoss: 0.040088\n",
      "Train Epoch: 2 [57300/60000 (96%)]\tLoss: 0.084715\n",
      "Train Epoch: 2 [57400/60000 (96%)]\tLoss: 0.064665\n",
      "Train Epoch: 2 [57500/60000 (96%)]\tLoss: 0.036167\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.033672\n",
      "Train Epoch: 2 [57700/60000 (96%)]\tLoss: 0.790442\n",
      "Train Epoch: 2 [57800/60000 (96%)]\tLoss: 0.085473\n",
      "Train Epoch: 2 [57900/60000 (96%)]\tLoss: 0.075212\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.097165\n",
      "Train Epoch: 2 [58100/60000 (97%)]\tLoss: 0.059803\n",
      "Train Epoch: 2 [58200/60000 (97%)]\tLoss: 0.350091\n",
      "Train Epoch: 2 [58300/60000 (97%)]\tLoss: 0.043835\n",
      "Train Epoch: 2 [58400/60000 (97%)]\tLoss: 0.731204\n",
      "Train Epoch: 2 [58500/60000 (98%)]\tLoss: 0.470012\n",
      "Train Epoch: 2 [58600/60000 (98%)]\tLoss: 0.287747\n",
      "Train Epoch: 2 [58700/60000 (98%)]\tLoss: 0.612463\n",
      "Train Epoch: 2 [58800/60000 (98%)]\tLoss: 0.485158\n",
      "Train Epoch: 2 [58900/60000 (98%)]\tLoss: 0.002966\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.077408\n",
      "Train Epoch: 2 [59100/60000 (98%)]\tLoss: 0.352021\n",
      "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.165844\n",
      "Train Epoch: 2 [59300/60000 (99%)]\tLoss: 0.001908\n",
      "Train Epoch: 2 [59400/60000 (99%)]\tLoss: 0.171309\n",
      "Train Epoch: 2 [59500/60000 (99%)]\tLoss: 0.247701\n",
      "Train Epoch: 2 [59600/60000 (99%)]\tLoss: 0.037027\n",
      "Train Epoch: 2 [59700/60000 (100%)]\tLoss: 0.073391\n",
      "Train Epoch: 2 [59800/60000 (100%)]\tLoss: 1.066827\n",
      "Train Epoch: 2 [59900/60000 (100%)]\tLoss: 0.244380\n",
      "\n",
      "Test set: Average loss: 0.0678, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.204208\n",
      "Train Epoch: 3 [100/60000 (0%)]\tLoss: 0.038434\n",
      "Train Epoch: 3 [200/60000 (0%)]\tLoss: 0.337836\n",
      "Train Epoch: 3 [300/60000 (0%)]\tLoss: 0.007629\n",
      "Train Epoch: 3 [400/60000 (1%)]\tLoss: 0.291422\n",
      "Train Epoch: 3 [500/60000 (1%)]\tLoss: 0.093048\n",
      "Train Epoch: 3 [600/60000 (1%)]\tLoss: 0.026526\n",
      "Train Epoch: 3 [700/60000 (1%)]\tLoss: 0.077457\n",
      "Train Epoch: 3 [800/60000 (1%)]\tLoss: 0.066757\n",
      "Train Epoch: 3 [900/60000 (2%)]\tLoss: 0.053683\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.066710\n",
      "Train Epoch: 3 [1100/60000 (2%)]\tLoss: 0.007623\n",
      "Train Epoch: 3 [1200/60000 (2%)]\tLoss: 0.174425\n",
      "Train Epoch: 3 [1300/60000 (2%)]\tLoss: 0.291068\n",
      "Train Epoch: 3 [1400/60000 (2%)]\tLoss: 0.266007\n",
      "Train Epoch: 3 [1500/60000 (2%)]\tLoss: 0.057994\n",
      "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.273035\n",
      "Train Epoch: 3 [1700/60000 (3%)]\tLoss: 0.438774\n",
      "Train Epoch: 3 [1800/60000 (3%)]\tLoss: 0.025520\n",
      "Train Epoch: 3 [1900/60000 (3%)]\tLoss: 0.237023\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.671305\n",
      "Train Epoch: 3 [2100/60000 (4%)]\tLoss: 0.120143\n",
      "Train Epoch: 3 [2200/60000 (4%)]\tLoss: 0.077622\n",
      "Train Epoch: 3 [2300/60000 (4%)]\tLoss: 0.140192\n",
      "Train Epoch: 3 [2400/60000 (4%)]\tLoss: 0.260425\n",
      "Train Epoch: 3 [2500/60000 (4%)]\tLoss: 0.013461\n",
      "Train Epoch: 3 [2600/60000 (4%)]\tLoss: 0.050182\n",
      "Train Epoch: 3 [2700/60000 (4%)]\tLoss: 0.099423\n",
      "Train Epoch: 3 [2800/60000 (5%)]\tLoss: 0.037480\n",
      "Train Epoch: 3 [2900/60000 (5%)]\tLoss: 0.084074\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.568650\n",
      "Train Epoch: 3 [3100/60000 (5%)]\tLoss: 0.207450\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.369922\n",
      "Train Epoch: 3 [3300/60000 (6%)]\tLoss: 0.051164\n",
      "Train Epoch: 3 [3400/60000 (6%)]\tLoss: 0.011995\n",
      "Train Epoch: 3 [3500/60000 (6%)]\tLoss: 0.285640\n",
      "Train Epoch: 3 [3600/60000 (6%)]\tLoss: 1.089787\n",
      "Train Epoch: 3 [3700/60000 (6%)]\tLoss: 0.020641\n",
      "Train Epoch: 3 [3800/60000 (6%)]\tLoss: 0.111641\n",
      "Train Epoch: 3 [3900/60000 (6%)]\tLoss: 0.181651\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.747154\n",
      "Train Epoch: 3 [4100/60000 (7%)]\tLoss: 0.064319\n",
      "Train Epoch: 3 [4200/60000 (7%)]\tLoss: 0.055635\n",
      "Train Epoch: 3 [4300/60000 (7%)]\tLoss: 0.635335\n",
      "Train Epoch: 3 [4400/60000 (7%)]\tLoss: 0.188443\n",
      "Train Epoch: 3 [4500/60000 (8%)]\tLoss: 0.254569\n",
      "Train Epoch: 3 [4600/60000 (8%)]\tLoss: 0.066273\n",
      "Train Epoch: 3 [4700/60000 (8%)]\tLoss: 0.105041\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.062918\n",
      "Train Epoch: 3 [4900/60000 (8%)]\tLoss: 0.229854\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.047432\n",
      "Train Epoch: 3 [5100/60000 (8%)]\tLoss: 0.099392\n",
      "Train Epoch: 3 [5200/60000 (9%)]\tLoss: 0.016784\n",
      "Train Epoch: 3 [5300/60000 (9%)]\tLoss: 0.070887\n",
      "Train Epoch: 3 [5400/60000 (9%)]\tLoss: 0.144521\n",
      "Train Epoch: 3 [5500/60000 (9%)]\tLoss: 0.307925\n",
      "Train Epoch: 3 [5600/60000 (9%)]\tLoss: 0.027187\n",
      "Train Epoch: 3 [5700/60000 (10%)]\tLoss: 0.537370\n",
      "Train Epoch: 3 [5800/60000 (10%)]\tLoss: 0.039728\n",
      "Train Epoch: 3 [5900/60000 (10%)]\tLoss: 0.224107\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.042941\n",
      "Train Epoch: 3 [6100/60000 (10%)]\tLoss: 0.090565\n",
      "Train Epoch: 3 [6200/60000 (10%)]\tLoss: 0.253744\n",
      "Train Epoch: 3 [6300/60000 (10%)]\tLoss: 0.154849\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.350811\n",
      "Train Epoch: 3 [6500/60000 (11%)]\tLoss: 0.131747\n",
      "Train Epoch: 3 [6600/60000 (11%)]\tLoss: 0.053398\n",
      "Train Epoch: 3 [6700/60000 (11%)]\tLoss: 0.248338\n",
      "Train Epoch: 3 [6800/60000 (11%)]\tLoss: 0.065501\n",
      "Train Epoch: 3 [6900/60000 (12%)]\tLoss: 0.117607\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.024415\n",
      "Train Epoch: 3 [7100/60000 (12%)]\tLoss: 0.166873\n",
      "Train Epoch: 3 [7200/60000 (12%)]\tLoss: 0.360149\n",
      "Train Epoch: 3 [7300/60000 (12%)]\tLoss: 0.006882\n",
      "Train Epoch: 3 [7400/60000 (12%)]\tLoss: 0.058756\n",
      "Train Epoch: 3 [7500/60000 (12%)]\tLoss: 0.005191\n",
      "Train Epoch: 3 [7600/60000 (13%)]\tLoss: 0.020864\n",
      "Train Epoch: 3 [7700/60000 (13%)]\tLoss: 0.334667\n",
      "Train Epoch: 3 [7800/60000 (13%)]\tLoss: 0.605696\n",
      "Train Epoch: 3 [7900/60000 (13%)]\tLoss: 0.031577\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.258120\n",
      "Train Epoch: 3 [8100/60000 (14%)]\tLoss: 0.081153\n",
      "Train Epoch: 3 [8200/60000 (14%)]\tLoss: 0.303645\n",
      "Train Epoch: 3 [8300/60000 (14%)]\tLoss: 0.037533\n",
      "Train Epoch: 3 [8400/60000 (14%)]\tLoss: 0.064305\n",
      "Train Epoch: 3 [8500/60000 (14%)]\tLoss: 0.104107\n",
      "Train Epoch: 3 [8600/60000 (14%)]\tLoss: 0.028798\n",
      "Train Epoch: 3 [8700/60000 (14%)]\tLoss: 0.119818\n",
      "Train Epoch: 3 [8800/60000 (15%)]\tLoss: 0.004627\n",
      "Train Epoch: 3 [8900/60000 (15%)]\tLoss: 0.076158\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.067199\n",
      "Train Epoch: 3 [9100/60000 (15%)]\tLoss: 0.011907\n",
      "Train Epoch: 3 [9200/60000 (15%)]\tLoss: 0.046991\n",
      "Train Epoch: 3 [9300/60000 (16%)]\tLoss: 0.010666\n",
      "Train Epoch: 3 [9400/60000 (16%)]\tLoss: 0.447551\n",
      "Train Epoch: 3 [9500/60000 (16%)]\tLoss: 0.024023\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.020845\n",
      "Train Epoch: 3 [9700/60000 (16%)]\tLoss: 0.030451\n",
      "Train Epoch: 3 [9800/60000 (16%)]\tLoss: 0.517634\n",
      "Train Epoch: 3 [9900/60000 (16%)]\tLoss: 0.512587\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.035135\n",
      "Train Epoch: 3 [10100/60000 (17%)]\tLoss: 0.067380\n",
      "Train Epoch: 3 [10200/60000 (17%)]\tLoss: 0.017096\n",
      "Train Epoch: 3 [10300/60000 (17%)]\tLoss: 0.109695\n",
      "Train Epoch: 3 [10400/60000 (17%)]\tLoss: 0.181181\n",
      "Train Epoch: 3 [10500/60000 (18%)]\tLoss: 0.859838\n",
      "Train Epoch: 3 [10600/60000 (18%)]\tLoss: 0.016430\n",
      "Train Epoch: 3 [10700/60000 (18%)]\tLoss: 0.362153\n",
      "Train Epoch: 3 [10800/60000 (18%)]\tLoss: 0.064156\n",
      "Train Epoch: 3 [10900/60000 (18%)]\tLoss: 0.363323\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 1.469039\n",
      "Train Epoch: 3 [11100/60000 (18%)]\tLoss: 0.236389\n",
      "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.010737\n",
      "Train Epoch: 3 [11300/60000 (19%)]\tLoss: 0.100714\n",
      "Train Epoch: 3 [11400/60000 (19%)]\tLoss: 0.204851\n",
      "Train Epoch: 3 [11500/60000 (19%)]\tLoss: 0.156403\n",
      "Train Epoch: 3 [11600/60000 (19%)]\tLoss: 0.077336\n",
      "Train Epoch: 3 [11700/60000 (20%)]\tLoss: 0.488564\n",
      "Train Epoch: 3 [11800/60000 (20%)]\tLoss: 0.980640\n",
      "Train Epoch: 3 [11900/60000 (20%)]\tLoss: 0.259460\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.202803\n",
      "Train Epoch: 3 [12100/60000 (20%)]\tLoss: 0.344871\n",
      "Train Epoch: 3 [12200/60000 (20%)]\tLoss: 0.221692\n",
      "Train Epoch: 3 [12300/60000 (20%)]\tLoss: 0.152986\n",
      "Train Epoch: 3 [12400/60000 (21%)]\tLoss: 0.166072\n",
      "Train Epoch: 3 [12500/60000 (21%)]\tLoss: 0.015889\n",
      "Train Epoch: 3 [12600/60000 (21%)]\tLoss: 0.011649\n",
      "Train Epoch: 3 [12700/60000 (21%)]\tLoss: 0.292300\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.157615\n",
      "Train Epoch: 3 [12900/60000 (22%)]\tLoss: 0.127919\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.733447\n",
      "Train Epoch: 3 [13100/60000 (22%)]\tLoss: 0.051442\n",
      "Train Epoch: 3 [13200/60000 (22%)]\tLoss: 0.109277\n",
      "Train Epoch: 3 [13300/60000 (22%)]\tLoss: 0.002303\n",
      "Train Epoch: 3 [13400/60000 (22%)]\tLoss: 0.096841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [13500/60000 (22%)]\tLoss: 0.612847\n",
      "Train Epoch: 3 [13600/60000 (23%)]\tLoss: 0.422129\n",
      "Train Epoch: 3 [13700/60000 (23%)]\tLoss: 0.007018\n",
      "Train Epoch: 3 [13800/60000 (23%)]\tLoss: 0.492480\n",
      "Train Epoch: 3 [13900/60000 (23%)]\tLoss: 0.147707\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.902118\n",
      "Train Epoch: 3 [14100/60000 (24%)]\tLoss: 0.167118\n",
      "Train Epoch: 3 [14200/60000 (24%)]\tLoss: 0.015259\n",
      "Train Epoch: 3 [14300/60000 (24%)]\tLoss: 0.135671\n",
      "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.071872\n",
      "Train Epoch: 3 [14500/60000 (24%)]\tLoss: 0.014847\n",
      "Train Epoch: 3 [14600/60000 (24%)]\tLoss: 0.018353\n",
      "Train Epoch: 3 [14700/60000 (24%)]\tLoss: 0.059613\n",
      "Train Epoch: 3 [14800/60000 (25%)]\tLoss: 0.640178\n",
      "Train Epoch: 3 [14900/60000 (25%)]\tLoss: 0.096612\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.188585\n",
      "Train Epoch: 3 [15100/60000 (25%)]\tLoss: 0.278384\n",
      "Train Epoch: 3 [15200/60000 (25%)]\tLoss: 0.237905\n",
      "Train Epoch: 3 [15300/60000 (26%)]\tLoss: 0.028503\n",
      "Train Epoch: 3 [15400/60000 (26%)]\tLoss: 0.201192\n",
      "Train Epoch: 3 [15500/60000 (26%)]\tLoss: 0.046977\n",
      "Train Epoch: 3 [15600/60000 (26%)]\tLoss: 0.173973\n",
      "Train Epoch: 3 [15700/60000 (26%)]\tLoss: 0.304577\n",
      "Train Epoch: 3 [15800/60000 (26%)]\tLoss: 0.024632\n",
      "Train Epoch: 3 [15900/60000 (26%)]\tLoss: 0.135653\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.008853\n",
      "Train Epoch: 3 [16100/60000 (27%)]\tLoss: 0.525190\n",
      "Train Epoch: 3 [16200/60000 (27%)]\tLoss: 0.006369\n",
      "Train Epoch: 3 [16300/60000 (27%)]\tLoss: 0.057692\n",
      "Train Epoch: 3 [16400/60000 (27%)]\tLoss: 0.241564\n",
      "Train Epoch: 3 [16500/60000 (28%)]\tLoss: 0.179724\n",
      "Train Epoch: 3 [16600/60000 (28%)]\tLoss: 0.497422\n",
      "Train Epoch: 3 [16700/60000 (28%)]\tLoss: 0.384421\n",
      "Train Epoch: 3 [16800/60000 (28%)]\tLoss: 0.037721\n",
      "Train Epoch: 3 [16900/60000 (28%)]\tLoss: 0.117894\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.384037\n",
      "Train Epoch: 3 [17100/60000 (28%)]\tLoss: 0.035829\n",
      "Train Epoch: 3 [17200/60000 (29%)]\tLoss: 0.344415\n",
      "Train Epoch: 3 [17300/60000 (29%)]\tLoss: 0.183662\n",
      "Train Epoch: 3 [17400/60000 (29%)]\tLoss: 0.183715\n",
      "Train Epoch: 3 [17500/60000 (29%)]\tLoss: 0.049655\n",
      "Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.038499\n",
      "Train Epoch: 3 [17700/60000 (30%)]\tLoss: 0.053453\n",
      "Train Epoch: 3 [17800/60000 (30%)]\tLoss: 0.373919\n",
      "Train Epoch: 3 [17900/60000 (30%)]\tLoss: 0.595723\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.158518\n",
      "Train Epoch: 3 [18100/60000 (30%)]\tLoss: 0.020964\n",
      "Train Epoch: 3 [18200/60000 (30%)]\tLoss: 0.266275\n",
      "Train Epoch: 3 [18300/60000 (30%)]\tLoss: 0.038166\n",
      "Train Epoch: 3 [18400/60000 (31%)]\tLoss: 0.298283\n",
      "Train Epoch: 3 [18500/60000 (31%)]\tLoss: 0.134024\n",
      "Train Epoch: 3 [18600/60000 (31%)]\tLoss: 0.060357\n",
      "Train Epoch: 3 [18700/60000 (31%)]\tLoss: 0.158570\n",
      "Train Epoch: 3 [18800/60000 (31%)]\tLoss: 0.022376\n",
      "Train Epoch: 3 [18900/60000 (32%)]\tLoss: 0.090749\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.464516\n",
      "Train Epoch: 3 [19100/60000 (32%)]\tLoss: 0.909012\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.123234\n",
      "Train Epoch: 3 [19300/60000 (32%)]\tLoss: 0.035360\n",
      "Train Epoch: 3 [19400/60000 (32%)]\tLoss: 0.051405\n",
      "Train Epoch: 3 [19500/60000 (32%)]\tLoss: 0.263389\n",
      "Train Epoch: 3 [19600/60000 (33%)]\tLoss: 0.160250\n",
      "Train Epoch: 3 [19700/60000 (33%)]\tLoss: 0.062813\n",
      "Train Epoch: 3 [19800/60000 (33%)]\tLoss: 0.059504\n",
      "Train Epoch: 3 [19900/60000 (33%)]\tLoss: 0.124849\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.064242\n",
      "Train Epoch: 3 [20100/60000 (34%)]\tLoss: 0.021318\n",
      "Train Epoch: 3 [20200/60000 (34%)]\tLoss: 0.183963\n",
      "Train Epoch: 3 [20300/60000 (34%)]\tLoss: 0.028263\n",
      "Train Epoch: 3 [20400/60000 (34%)]\tLoss: 0.055938\n",
      "Train Epoch: 3 [20500/60000 (34%)]\tLoss: 0.189298\n",
      "Train Epoch: 3 [20600/60000 (34%)]\tLoss: 0.214995\n",
      "Train Epoch: 3 [20700/60000 (34%)]\tLoss: 0.030458\n",
      "Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.447951\n",
      "Train Epoch: 3 [20900/60000 (35%)]\tLoss: 0.311383\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.165282\n",
      "Train Epoch: 3 [21100/60000 (35%)]\tLoss: 0.201920\n",
      "Train Epoch: 3 [21200/60000 (35%)]\tLoss: 1.226860\n",
      "Train Epoch: 3 [21300/60000 (36%)]\tLoss: 0.686295\n",
      "Train Epoch: 3 [21400/60000 (36%)]\tLoss: 0.039294\n",
      "Train Epoch: 3 [21500/60000 (36%)]\tLoss: 0.183928\n",
      "Train Epoch: 3 [21600/60000 (36%)]\tLoss: 0.537352\n",
      "Train Epoch: 3 [21700/60000 (36%)]\tLoss: 0.156521\n",
      "Train Epoch: 3 [21800/60000 (36%)]\tLoss: 0.212789\n",
      "Train Epoch: 3 [21900/60000 (36%)]\tLoss: 0.002169\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.263474\n",
      "Train Epoch: 3 [22100/60000 (37%)]\tLoss: 0.378963\n",
      "Train Epoch: 3 [22200/60000 (37%)]\tLoss: 0.079427\n",
      "Train Epoch: 3 [22300/60000 (37%)]\tLoss: 0.702988\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.071601\n",
      "Train Epoch: 3 [22500/60000 (38%)]\tLoss: 0.224559\n",
      "Train Epoch: 3 [22600/60000 (38%)]\tLoss: 0.254583\n",
      "Train Epoch: 3 [22700/60000 (38%)]\tLoss: 0.284540\n",
      "Train Epoch: 3 [22800/60000 (38%)]\tLoss: 0.112567\n",
      "Train Epoch: 3 [22900/60000 (38%)]\tLoss: 0.214758\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.593385\n",
      "Train Epoch: 3 [23100/60000 (38%)]\tLoss: 0.260359\n",
      "Train Epoch: 3 [23200/60000 (39%)]\tLoss: 0.121438\n",
      "Train Epoch: 3 [23300/60000 (39%)]\tLoss: 0.071885\n",
      "Train Epoch: 3 [23400/60000 (39%)]\tLoss: 0.286662\n",
      "Train Epoch: 3 [23500/60000 (39%)]\tLoss: 0.011832\n",
      "Train Epoch: 3 [23600/60000 (39%)]\tLoss: 0.182701\n",
      "Train Epoch: 3 [23700/60000 (40%)]\tLoss: 0.149550\n",
      "Train Epoch: 3 [23800/60000 (40%)]\tLoss: 0.239125\n",
      "Train Epoch: 3 [23900/60000 (40%)]\tLoss: 0.320891\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.241024\n",
      "Train Epoch: 3 [24100/60000 (40%)]\tLoss: 0.189501\n",
      "Train Epoch: 3 [24200/60000 (40%)]\tLoss: 0.065909\n",
      "Train Epoch: 3 [24300/60000 (40%)]\tLoss: 0.192816\n",
      "Train Epoch: 3 [24400/60000 (41%)]\tLoss: 1.228605\n",
      "Train Epoch: 3 [24500/60000 (41%)]\tLoss: 0.003457\n",
      "Train Epoch: 3 [24600/60000 (41%)]\tLoss: 0.443921\n",
      "Train Epoch: 3 [24700/60000 (41%)]\tLoss: 0.108421\n",
      "Train Epoch: 3 [24800/60000 (41%)]\tLoss: 0.242171\n",
      "Train Epoch: 3 [24900/60000 (42%)]\tLoss: 0.216298\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.141218\n",
      "Train Epoch: 3 [25100/60000 (42%)]\tLoss: 0.625993\n",
      "Train Epoch: 3 [25200/60000 (42%)]\tLoss: 0.423075\n",
      "Train Epoch: 3 [25300/60000 (42%)]\tLoss: 0.093786\n",
      "Train Epoch: 3 [25400/60000 (42%)]\tLoss: 0.127777\n",
      "Train Epoch: 3 [25500/60000 (42%)]\tLoss: 0.220169\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.013075\n",
      "Train Epoch: 3 [25700/60000 (43%)]\tLoss: 0.022223\n",
      "Train Epoch: 3 [25800/60000 (43%)]\tLoss: 0.093305\n",
      "Train Epoch: 3 [25900/60000 (43%)]\tLoss: 0.018649\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.794723\n",
      "Train Epoch: 3 [26100/60000 (44%)]\tLoss: 0.411757\n",
      "Train Epoch: 3 [26200/60000 (44%)]\tLoss: 0.183329\n",
      "Train Epoch: 3 [26300/60000 (44%)]\tLoss: 0.604946\n",
      "Train Epoch: 3 [26400/60000 (44%)]\tLoss: 0.307045\n",
      "Train Epoch: 3 [26500/60000 (44%)]\tLoss: 0.232700\n",
      "Train Epoch: 3 [26600/60000 (44%)]\tLoss: 0.027028\n",
      "Train Epoch: 3 [26700/60000 (44%)]\tLoss: 0.189954\n",
      "Train Epoch: 3 [26800/60000 (45%)]\tLoss: 0.772990\n",
      "Train Epoch: 3 [26900/60000 (45%)]\tLoss: 0.146181\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.211817\n",
      "Train Epoch: 3 [27100/60000 (45%)]\tLoss: 0.148035\n",
      "Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.062514\n",
      "Train Epoch: 3 [27300/60000 (46%)]\tLoss: 0.032999\n",
      "Train Epoch: 3 [27400/60000 (46%)]\tLoss: 0.135488\n",
      "Train Epoch: 3 [27500/60000 (46%)]\tLoss: 0.142865\n",
      "Train Epoch: 3 [27600/60000 (46%)]\tLoss: 0.059320\n",
      "Train Epoch: 3 [27700/60000 (46%)]\tLoss: 0.320475\n",
      "Train Epoch: 3 [27800/60000 (46%)]\tLoss: 0.058381\n",
      "Train Epoch: 3 [27900/60000 (46%)]\tLoss: 0.177285\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.006884\n",
      "Train Epoch: 3 [28100/60000 (47%)]\tLoss: 0.045182\n",
      "Train Epoch: 3 [28200/60000 (47%)]\tLoss: 0.146393\n",
      "Train Epoch: 3 [28300/60000 (47%)]\tLoss: 0.474533\n",
      "Train Epoch: 3 [28400/60000 (47%)]\tLoss: 0.555080\n",
      "Train Epoch: 3 [28500/60000 (48%)]\tLoss: 0.321166\n",
      "Train Epoch: 3 [28600/60000 (48%)]\tLoss: 0.007604\n",
      "Train Epoch: 3 [28700/60000 (48%)]\tLoss: 0.032989\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.021965\n",
      "Train Epoch: 3 [28900/60000 (48%)]\tLoss: 0.027331\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.027709\n",
      "Train Epoch: 3 [29100/60000 (48%)]\tLoss: 0.031477\n",
      "Train Epoch: 3 [29200/60000 (49%)]\tLoss: 0.268103\n",
      "Train Epoch: 3 [29300/60000 (49%)]\tLoss: 0.234060\n",
      "Train Epoch: 3 [29400/60000 (49%)]\tLoss: 0.614056\n",
      "Train Epoch: 3 [29500/60000 (49%)]\tLoss: 0.343488\n",
      "Train Epoch: 3 [29600/60000 (49%)]\tLoss: 0.003196\n",
      "Train Epoch: 3 [29700/60000 (50%)]\tLoss: 0.586515\n",
      "Train Epoch: 3 [29800/60000 (50%)]\tLoss: 0.043099\n",
      "Train Epoch: 3 [29900/60000 (50%)]\tLoss: 0.062958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.053319\n",
      "Train Epoch: 3 [30100/60000 (50%)]\tLoss: 0.059222\n",
      "Train Epoch: 3 [30200/60000 (50%)]\tLoss: 0.214712\n",
      "Train Epoch: 3 [30300/60000 (50%)]\tLoss: 0.008199\n",
      "Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.162644\n",
      "Train Epoch: 3 [30500/60000 (51%)]\tLoss: 0.766961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nicolas/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [30600/60000 (51%)]\tLoss: 0.084179\n",
      "Train Epoch: 3 [30700/60000 (51%)]\tLoss: 0.095427\n",
      "Train Epoch: 3 [30800/60000 (51%)]\tLoss: 0.458228\n",
      "Train Epoch: 3 [30900/60000 (52%)]\tLoss: 0.070295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 12714) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2910\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2911\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-8b22a0ce90c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-8b22a0ce90c8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-8b22a0ce90c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1827\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1831\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1371\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1279\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             )\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1128\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mformatted_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records, last_unique, recursion_repeat)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_unique\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_record\u001b[0;34m(self, frame, file, lnum, func, lines, index)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinereader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0;31m# build composite names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mname_cont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                         \u001b[0;31m# Continuation of a dotted name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 12714) exited unexpectedly with exit code 1."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    if args.cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 6\n",
       " 8\n",
       " 0\n",
       " 5\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 5\n",
       " 8\n",
       "[torch.LongTensor of size 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
